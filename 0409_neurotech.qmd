---
title: "Developing a 'Smart' Recovery \n\nMonitoring and Support System"
author: "John J. Curtin, Ph.D."
institute: "University of Wisconsin-Madison"
date: "April 9, 2025"
editor_options: 
  chunk_output_type: console
---

::: {.notes}
About a decade ago I was approaching the middle of my career. I had developed a successful basic clinical science research program as a psychophysiologist running experiments to understand the effects of drugs and drug withdrawal on stress. 

The work was intellectually stimulating, we were publishing it in good outlets, and we were getting grants, but my heart was increasingly not in it.
:::

-----------------------------------------------------------------------------

::: {.notes}
I’d become a clinical psychologist to help people struggling with alcohol and other SUDs.

My paternal grandmother died of complications secondary to alcoholism.

My dad has struggled with his use of alcohol for his entire adult life and during periods where he lost control it affected all of us.

My cousin, Stephen, has a severe substance use disorder and has been incarcerated several times for drug related offenses. He has had periods of stability but they have always ended in another relapse.
:::

-----------------------------------------------------------------------------

::: {.notes}
My Aunt Cathy and Stephen’s brother, Colin, had reached out to me on numerous occasions to ask what could be done to help Stephen.

And it was those conversations that really got me thinking about how I could re-direct my research program to help people like Stephen and my dad and my grandmother. 
:::

-----------------------------------------------------------------------------

## Precision Mental Health for Continuing Care

![](https://github.com/jjcurtin/slide_decks/blob/main/images/gustafson.jpeg?raw=true){.absolute bottom=0 right=10 width=4in}

::: {.notes}
It was around that time that my colleague, Dave Gustafson, reached out to me.  Dave directs a center at UW that develops digital therapeutics for substance use disorders.  These are essentially smartphone apps that provide ongoing continuing care for patients during their recovery.  He had just completed a large randomized controlled trial demonstrating that his app meaningfully decreased heavy drinking days and increased abstinence rates over the first year of recovery.

However, he also noticed many of the people who had relapsed hadn't used the app in the days leading up to that relapse.  And others who had relapsed hadn't used the specific supports in the app that he would have thought would be most effective for them.
:::

-----------------------------------------------------------------------------

## Precision Mental Health for Continuing Care


\
\

> “Could you predict not only [who]{.uwred} might be at greatest risk for relapse … <br>
 … but precisely [when]{.uwred} that relapse might occur … <br>
 … and how [best to intervene]{.uwred} to prevent it?"
 
 \
 \
![](https://github.com/jjcurtin/slide_decks/blob/main/images/gustafson.jpeg?raw=true){.absolute bottom=0 right=10 width=4in}

::: {.notes}
Dave knew that we were exploring the factors that motivated alcohol and other drug use and he asked us a simple question: 

"Could you predict not only who might be at greatest risk for relapse but precisely when that relapse might occur and how best to intervene to prevent it"

... because if we could develop a system to do this, he could embed it into his app to guide people to the most effective supports at the most critical moments in their recovery
:::


-----------------------------------------------------------------------------

## Precision Mental Health for Continuing Care 

\

Precision mental health requires us to provide the [right interventions]{.uwred} and supports to the [right people]{.uwred} at the [right time]{.uwred}, [every time]{.uwred}

\

SUD continuing care requires 

- Long-term monitoring
- Ongoing lifestyle adjustments and support

::: {.notes}
These questions that Dave was asking are at the heart of what we now call precision mental health.  How can we provide the **right interventions and supports** to the **right people** at the **right time**, **every time**​

And this focus on the **right time** is particularly important for recovery from substance use disorders.  Substance use disorders are chronic relapsing conditions and therefore successful recovery requires lifelong monitoring and support to prevent relapse.

And, critically, the optimal supports for any specific individual can change month to month, day to day, and even from moment to moment.
:::


-----------------------------------------------------------------------------


## Precision Mental Health for Continuing Care 

\

[Precision mental health requires us to provide the right interventions and supports to the right people at the right time, every timed]{.gray}

\

[SUD continuing care requires ]{.gray}

- [Long-term monitoring]{.gray}
- [Ongoing lifestyle adjustments and support]{.gray}

\

A "Smart" Recovery Monitoring and Support System can provide temporally precise, dynamic, personalized continuing care by combining:

- Sensing
- Artificial Intelligence/Machine learning

::: {.notes}
And it goes without saying that this is hard and its why lapses and relapse are so common for so many people in recovery.

But we believed that we could harness and combine two technologies that were emerging at that time, personal sensing and artificial intelligence algorithms,
to develop a smart recovery monitoring and support system that could both predict lapses before they occurred and provide personalized support and recommendations to patients about how to prevent those lapses from occurring.

And what I'd like to do today is tell you a bit more about how we are doing this, what we have learned so far, and where we are going next with this system
:::

-----------------------------------------------------------------------------

## Model Output: Lapses 

\

Lapses

- are clearly defined,
- have a temporally precise onset, and
- can serve as an early warning sign for relapse (precede and predict)

\

- "Abstinence violation effects" can increase relapse risk
- Even a single lapse can result in overdose and/or death for some drugs

::: {.notes}
[PAUSE]

OK - so how do we develop this Recovery Monitoring and Support System?

To start, we have begun to develop risk prediction models that focus both on **predicting** and **explaining** future lapses

Our focus is on future lapses rather than other clinically meaningful outcomes like substance use related problems or full blown relapse for several reasons.
:::

-----------------------------------------------------------------------------

## Model Output: Lapses 

\

Lapses

- are clearly defined,
- have a temporally precise onset, and
- can serve as an early warning sign for relapse (precede and predict)

\

- "Abstinence violation effects" can increase relapse risk
- Even a single lapse can result in overdose and/or death for some drugs

::: {.notes}
To start, lapses are

- Clearly defined and have a temporally precise onset
- They can serve as an early warning sign for relapse because they both precede and predict it

- Lapses are also important targets for intervention because we know that maladaptive thoughts and feelings following a lapse - often called abstinence violation effects - can start a downward spiral that leads to relapse by itself if not addressed   

- And sadly, for some drugs, even a single lapse can result in overdose and death


So for these reasons, we are developing risk models that predict the probability of a future lapse
:::

-----------------------------------------------------------------------------

## Model Inputs: Personal Sensing

\

Personal sensing collects information from smartphones and wearable sensors to identify a person’s [thoughts, feelings, behaviors, and context]{.uwred}.

::: {.notes}
[PAUSE]

The next logical set of questions surround the model inputs.   

What will we use as inputs or risk features in these models to predict lapses? And how will we measure the raw signals associated with these risk features?

We believe that personal sensing will play a big role here.  

Personal sensing is just a fancy term for a broad category of methods that allow us to do real-world monitoring of people's thoughts, feelings,       behaviors, and context.
:::

-----------------------------------------------------------------------------

## Model Inputs: Personal Sensing

\

[Personal sensing collects information from smartphones and wearable sensors to identify a person’s thoughts, feelings, behaviors, and context.]{.gray}

\

Sensing allows for "real-world" measurement that

- Can be sustained for long periods
- Has very high temporal granularity

::: {.notes}
These methods allow us to collect these inputs over very long periods of   time from months to even years, which is critical for SUDs because they    are chronic, relapsing disorders that require lifetime management and      continuing care.

and we can collect these inputs with very high temporal granularity, at    least several times per day and in some instances continuously, which is   also very important so that we have the temporal precision to intervene    during days and even potentially moments of heightened risk.
:::

-----------------------------------------------------------------------------

## Model Inputs: Personal Sensing

\

[Personal sensing collects information from smartphones and other sensors to identify a person’s thoughts, feelings, behaviors, and context.]{.gray}

\

[Sensing allows for "real-world" measurement that]{.gray}

- [Can be sustained for long periods]{.gray}
- [Has very high temporal granularity]{.gray}

\

Practical requirements

- Feasible/acceptable for long term use
- Consistent across platforms/devices
- Stable/Low churn over time in necessary hardware/software 

::: {.notes}
There are also some practical requirements.  

If we are going to make our recovery monitoring and support system widely available, then the measurement must be feasible and acceptable to people  for long term use.

And the measurements must also be consistent and stable across common equipment that most people own.
:::

-----------------------------------------------------------------------------

## Model Inputs: Personal Sensing

\

We use smartphone sensing methods to collect

- Ecological Momentary Assessments (EMA)
- Contextualized Geolocation
- Contexualized Smartphone Communications

::: {.notes}
From our perspective, these requirements limit us to sensing methods that use only smartphones with the major operating systems but I'd be happy to talk more about this decision and the experiences we have had with other sensing methods that we have explored during the discussion period if there is interest.

[PAUSE]

These same requirements have also focused our smartphone sensing efforts on three separate but complementary sets of raw signals that we believe can be used to derive many important lapse risk features to input to our prediction models.  These raw signals are

- Ecological momentary assessments
- Geolocation
- Cellular communications meta data and text message content
:::

-----------------------------------------------------------------------------

## Model Inputs: Personal Sensing

\

We use smartphone sensing methods to collect

- Ecological Momentary Assessments (EMA)
- Contextualized Geolocation
- Contexualized Smartphone Communications

::: {.notes}
Our broad goal is to use features from these powerful signals to develop a recovery monitoring and support system that can BOTH

- predict future lapses with exceptionally high temporal resolution AND

- understand the risk factors contributing to those predicted lapses so that we can recommend personalized recovery activities, supports, and lifestyle adjustments in advance of those lapses to prevent them.

And critically, this system must perform well enough to be useful when applied to individuals.

In other words, we are not looking to find coarse group-level predictors of lapses but instead to make predictions for specific individuals at specific moments in time that are actionable and useful for them.
:::

-------------------------------------------------------------------------

## Lapse Prediction for AUD

\

::: {.columns}
:::: {.column width="60%"}
- 151 individuals with moderate to severe AUD

\

- Early in recovery (1-8 weeks)

\

- Committed to abstinence throughout study

\

- Followed with sensing for up to 3 months
  - Ecological Momentary Assessments
  - Contextualized Geolocation
  - Contexualized Smartphone Communications
  - (also sensed physiology, sleep, coarse self-report)
  
::::

:::: {.column width="40%"}
![risk1_pis.png](https://github.com/jjcurtin/lectures/blob/main/images/risk1_pis.png?raw=true)\    
![niaaa_logo.png](https://github.com/jjcurtin/lectures/blob/main/images/niaaa_logo.png?raw=true)\    
::::
:::

::: {.notes}
So let me transition now to describing the progress we have made so far to develop this recovery monitoring and support system for SUD

As the first step, in 2020 we completed a first NIAAA funded project where we recruited 151 participants who were in early recovery from a moderate to severe alcohol use disorder.

These participants were committed to abstinence at the start of the study and we followed them for up to three months, using our three sensing methods and also recording any lapses back to alcohol use.
:::

-----------------------------------------------------------------------------

## Lapse Prediction for AUD

\

::: {.columns}
:::: {.column width="60%"}
- 151 individuals with moderate to severe AUD

\

- Early in recovery (1-8 weeks)

\

- Committed to abstinence throughout study

\

- Followed with sensing for up to 3 months
  - [Ecological Momentary Assessments]{.uwred}
  - Contextualized Geolocation
  - Contexualized Smartphone Communications
  - (also sensed physiology, sleep, coarse self-report)
::::

:::: {.column width="40%"}
![risk1_pis.png](https://github.com/jjcurtin/lectures/blob/main/images/risk1_pis.png?raw=true)\    
![niaaa_logo.png](https://github.com/jjcurtin/lectures/blob/main/images/niaaa_logo.png?raw=true)\    
::::
:::

::: {.notes}
[PAUSE]

We are in the early stages of model building at this point and I will focus today primarily on results from preliminary models using only EMA.  

However, we are actively working with GPS and cellular communications as well and I will give you a clear sense of how we are developing models with those signals too.  

I'll also give you more detail about how we think we can implement these models for clinical benefits.  
:::

-----------------------------------------------------------------------------

## Participant Characteristics

```{r}
#| label: figs_ema_demographics
#| fig-height: 6
#| fig-width: 10

source(here::here("figs/risk/figs_ema_demographics.R"))
cowplot::plot_grid(fig_age, fig_income, fig_sex_bar,
                   fig_educ_bar, fig_ms_bar, fig_race_bar, nrow = 2, ncol  = 3)
```

::: {.notes}
Let me start highlighting the characteristics of the sample we are using to develop and evaluate the AUD lapse models.

We had reasonble diversity across many participant charactersitics including age, sex at birth, martital status, education, and income

However, given the methods we used for recruiting, we have very little racial and ethinic diversity in the sample.  The sample is predominately white and non-hispanic

I'll return to this later both when we evaluate issues of algorithmic fairness and when I talk about another, larger NIDA funded project where we are correcting this issue of racial and ethnic representation in our models.  
:::

-----------------------------------------------------------------------------

## Participant Characteristics

::: {.columns}
:::: {.column width="50%"}

\

- All participants met criteria for moderate to severe AUD

\

- Reported abstinence goals
::::

:::: {.column width="50%"}
```{r}
#| label: figs_sx
#| fig-height: 6
#| fig-width: 6 

# plot made in fig_demographics.R
fig_sx
```
::::
:::

::: {.notes}
I also want to highlight that this is a sample with clinically meaningful problems with their AUD use, consistent with their pursuit of abstinence goals

On the right, I am showing you a histogram of the DSM-5 AUD symptom counts to confirm that everyone reported 4 or more symptoms of alcohol use disorder consistent with a moderate to severe presentation
:::

-----------------------------------------------------------------------------

## Ecological Momentary Assessments 

\

- Current/Recent Experiences
  - Craving
  - Emotional state 
  - Recent past alcohol use
  - Recent risky situations
  - Recent stressful events
  - Recent pleasant event

\

- Future Expectations
  - Risky situations
  - Stressful events
  - Abstinence Confidence

![](https://github.com/jjcurtin/slide_decks/blob/main/images/ema_hand.png?raw=true){.absolute bottom=0 right=50 width=45%}


::: {.notes}
So let me tell you a bit more about the ecological momentary assessments (or EMAs) that we used as part of our sensing methods. These EMAs are brief surveys that participants completed on their smartphones. They take 20-30 seconds to complete and we collected them several times per day.

On each EMA, participants reported the date and time of any lapses back to alcohol use that they hadn’t previously reported. These lapse reports are used for the lapse outcomes that we train our models to predict.  And these laspes were also confirmed by study staff during lab visits using a follow-back procedure.

All of the EMAs also asked participants about their current craving, emotional state, recent risky situations, and recent stressful and pleasant events since their last EMA.

And on the first EMA each day, they also reported any future risky situations and stressful events that they expected in the next week and their confidence that they would remain abstinent. 
:::

-----------------------------------------------------------------------------

## Modeling: Predictions 

\

- Predict hour-by-hour probability of [future lapse]{.uwred}

\

- Lapse window widths
  - 1 week 
  - 1 day
  - 1 hour 

::: {.notes}
OK, now that we've talked about sensing, I want to transition to training models to use features from these raw signals to predict lapses.

For our purposes today I wont dive deep into the machine learning methods but let me highlight a few high level details 

We used features from these sensed signals that I just described to make predictions about the hour-by-hour probability of a future lapse.  We are developing separate models for three future lapse windows – lapses in the next week, lapses in the next day, and lapses in the next hour.  
:::

-----------------------------------------------------------------------------

## Modeling: Predictions 

\

- Predict hour-by-hour probability of [future lapse]{.uwred}

\

- Lapse window widths
  - 1 week 
  - 1 day
  - 1 hour 

::: {.notes}
For example, if I was in recovery from an AUD, I could use these models to generate the probability that I would lapse after I leave the presentation today at 7pm. One model would generate the probability I would lapse at some point between 7 pm today and 7 pm next Wednesday, the second would predict the probability of a lapse between 7 pm today and 7 pm tomorrow and the third and most temporally precise model would provide the probability of a lapse in the next hour, between 7pm today and 8pm today.  

And of course, all of the models would only use data collected prior to 7 pm today so that they are “predicting”, in the full sense of the word, into the future and not just demonstrating an association.
:::
-----------------------------------------------------------------------------

## Modeling: Algorithms and Resampling

\

- XGBoost - Boosted decision trees
- Also considered:
  - ElasticNet GLM (e.g., LASSO, ridge regression)
  - Random Forest
  - KNN

\

- Using grouped (by participant), nested, repeated k-fold CV 
  - 30 "held-out" test sets
  - New participants and observations not used for training

::: {.notes}
We are evaluating machine learning model configurations that differ by common statistical algorithms that I can talk more about later if there is interest.

And we are rigorously evaluating the performance of these models using grouped, nested, repeated k-fold cross validation.  

For our purposes, what this means is that we evaluate model performance in 30 separate held out test sets and each of these sets contain new observations from new participants that were not used to train the models.  

And again, this is consistent with what we mean by prediction.  We don't care how our models perform with the participants we used to train them. We want to know how well the models will work when we implement them with new people in the future.
:::

-----------------------------------------------------------------------------

## Modeling: Feature Engineering 

\

- Features based on recent past experiences (12, 24, 48, 72, 168 hours)

\

- Min, max, and median response (all items)

\

- History (count) of past lapses (item 1) and completed EMAs (compliance)

\

- Raw scores and change scores (from baseline/all past responses)

::: {.notes}
We used the raw responses to the EMAs to engineer about 300 features to use in our models to predict future lapses

We formed features by aggregating EMA items over various past time periods ranging from 12 - 168 hours in the past relative to the window we want to predict into.

We calculated mins, maxes and medians for the EMA items in these time periods

We also calculated counts of past lapses and counts of past EMAs completed to index engagment with our monitoring system.

And we included these scores both in raw form and as change from baselines for the participant based on all their previous responses since the start of the study.
:::

-----------------------------------------------------------------------------

## Predicted Lapse Probabilities: Next Week Model

::: {.columns}
:::: {.column width="50%"}

\

- Model predicts [probability]{.uwred} of lapse in next week for “[new]{.uwred} observations in test sets

\

- Can panel predictions by [Ground Truth]{.uwred} (i.e., true lapse vs. no lapse observations

\

- Want high probabilities for true lapses and low probabilities for true no lapses
::::

:::: {.column width="50%"}
<!--Lapse Probability by Ground Truth"-->
```{r}
#| label: fig_hist_week
#| fig-height: 6
#| fig-width: 8

source(here::here("figs/risk/figs_ema_probability.R"))
fig_hist_week
```
::::
:::

::: {.notes}
OK, lets begin to explore how well we can do.

Lets start with the model that provides the coarsest level of temporal specificity – 1 week, and let me take a moment to make the predictions that this machine learning model provides more concrete for you

On the right, you are looking at histograms of the lapse probability predictions that the model makes for all the weeks for all the patients in the held out folds.   

I’ve paneled these histograms by whether a lapse did or did not happen in reality for each predicted week.  The top panel is for weeks with lapses and the bottom panel is for weeks with no lapses.

Ideally, you want the predicted probabilities to be very high for weeks when there was a lapse and very low for weeks when there was no lapse.    

And this is exactly what we see for the one week lapse window model
:::

-----------------------------------------------------------------------------

## Model Performance: Area under ROC curve (auROC) 

\

The Area under the Receiver Operating Characteristic Curve (auROC) indicates the probability that any true lapse is scored higher than any true no-lapse by the model

- Random performance:  auROC = 0.5 
- Perfect performance: auROC = 1.0 

::: {.columns}
:::: {.column width="40%"}
![](https://github.com/jjcurtin/slide_decks/blob/main/images/auroc_rules.jpeg?raw=true){.absolute bottom=20 left=20 width=30%}
::::
:::: {.column width="60%"}
<!--BLANK-->
::::
:::

::: {.notes}
But we can quantify the performance of our models more precisely with a performance metric called the Area under the Receiver Operating Characteristic curve or auROC for short.

The auROC is a measure of the model's ability to discriminate between true lapse and no-lapse observations when making lapse probability predictions.  

The auROC can range from 0.5 to 1.0 where an auROC of .5 indicates a model whose accuracy is no better than random guessing, 

and an auROC of 1.0 indicates perfect accuracy 

And models with auROCs of .90 or higher are considered to have excellent performance.
:::

-----------------------------------------------------------------------------

## Model Performance: Area under ROC curve (auROC) 

\

The Area under the Receiver Operating Characteristic Curve (auROC) indicates the probability that any true lapse is scored higher than any true no-lapse by the model

- Random performance:  auROC = 0.5 
- Perfect performance: auROC = 1.0 

::: {.columns}
:::: {.column width="40%"}
![](https://github.com/jjcurtin/slide_decks/blob/main/images/auroc_rules.jpeg?raw=true){.absolute bottom=20 left=20 width=30%}
::::

:::: {.column width="60%"}
<!--BLANK-->
::::
:::

::: {.notes}

[PAUSE]

but the auROC also has an intuitive interpretation that I want you to understand.  

Its value represents the probability that any randomly selected positive observation, in our case, a lapse, will be assigned a higher lapse probability score than a randomly selected negative observation where no lapse occurs.

So, for example, that random classifier with an auROC of 0.5 would only have a 50% chance of predicting a higher lapse risk score for any specific lapse vs. a no-lapse period.  

And conversely, the perfect classifier would have a 100% chance of scoring that lapse higher than a no-lapse observation. 
:::

-----------------------------------------------------------------------------

## Model Performance: Next Week Model

::: {.columns}
:::: {.column width="40%"}
![](https://github.com/jjcurtin/slide_decks/blob/main/images/auroc_rules.jpeg?raw=true){.absolute bottom=20 left=20 width=30%}
::::

:::: {.column width="60%"}
```{r}
#| label: figs_auroc_ci_1
#| fig-height: 6
#| fig-width: 6

source(here::here("figs/risk/figs_ema_probability.R"))
fig_auroc_ci_1
```
::::
:::

::: {.notes}
So given this, we were very excited to see that our one week prediction model had excellent performance with an auROC of approximately .90, which indicates that there is a 90% chance that the model will score a lapse higher than a no-lapse period.  

This exceeded the performance of the only other published week level lapse prediction model that we were aware of.   

But we were also eager to see how well we could do if we required a higher level of temporal precision by developing a day level model.
:::

-----------------------------------------------------------------------------

## Model Performance: Next Day Model

::: {.columns}
:::: {.column width="40%"}
![](https://github.com/jjcurtin/slide_decks/blob/main/images/auroc_rules.jpeg?raw=true){.absolute bottom=20 left=20 width=30%}
::::

:::: {.column width="60%"}
```{r}
#| label: figs_auroc_ci_2
#| fig-height: 6
#| fig-width: 6

fig_auroc_ci_2
```
::::
:::

::: {.notes}
And our model that made predictions about the lapse probability in the next day performed even better that the week level model, with an auROC of .91.
:::

-----------------------------------------------------------------------------

## Model Performance: Next Hour Model

::: {.columns}
:::: {.column width="40%"}
![](https://github.com/jjcurtin/slide_decks/blob/main/images/auroc_rules.jpeg?raw=true){.absolute bottom=20 left=20 width=30%}
::::

:::: {.column width="60%"}
```{r}
#| label: figs_auroc_ci_3
#| fig-height: 6
#| fig-width: 6

fig_auroc_ci_3
```
::::
:::

::: {.notes}
and our one hour model had the highest performance of all with an auROC of 0.93.

Candidly, we hadn’t anticipated that we could do this well with such high levels of temporal precision.

But we can, and to be clear, we believe all three of these models to have clinically implementable levels of performance such that we can use them to make meaningful decisions for individual participants at specific moments in time if we can embed these models within a recovery monitoring and support system. 
:::

-----------------------------------------------------------------------------

## Understanding the Models


::: {.notes}

[PAUSE]

Of course, if we want to implement these models in a real world system, we need to understand how they work and what features are driving the predictions.  And in recent years, the field of interpretable AI has made big strides in developing tools to help us look under the hood, so to speak, of these models to better understand them.

One of the more promising of these tools is SHAP or Shapley Additive Explanations.  SHAP is a method for interpreting the output of machine learning models that is based on cooperative game theory.  It provides a principled way to assign each feature or category of features an importance value for a particular prediction. 

We can use this approach to understand why the model makes a specific prediction for a specific participant at a specific moment in time.  And I will do this a bit later when we talk about how to make personalized support recommends.  

But we can also use it to understand the global feature importance of each feature across all participants and observations for any of our models, so lets take a look at this first.
:::

-----------------------------------------------------------------------------

## Understanding the Models: Next Hour Model

::: {.columns}
:::: {.column width="40%"}

\

- All EMA items impact lapse probability
::::

:::: {.column width="60%"}
```{r}
#| label: figs_global_all-1
#| fig-height: 6
#| fig-width: 8

source(here::here("figs/risk/figs_ema_shaps.R"))
fig_global_hour
```
::::
:::

::: {.notes}

[PAUSE]

The plot on the right shows feature categories and their associated importance as indexed by mean absolute SHAP values across all the predictions made by the Next Hour Model. 

The bar width shows the relative importance of each feature, globally across all participants and observations.  From this we see a few important characteristics of the NEXT HOUR model.   

First, all of EMA items affect predictions about lapse probability across observations.  

As you might expect, history of past lapses has a big influence on the probability of a future lapse.  But self reported abstinence efficacy, craving, emotional state, history of stressful events, and other features from the EMA all make meaningful contributions to lapse probability in the next hour across observations.  
:::
-----------------------------------------------------------------------------

## Understanding the Models: Next Hour Model

::: {.columns}
:::: {.column width="40%"}

\

- [All EMA items impact lapse probability]{.gray}

\

- Lapse day and lapse hour are useful
::::

:::: {.column width="60%"}
```{r}
#| label: figs_global_all-2
#| fig-height: 6
#| fig-width: 8

fig_global_hour
```
::::
:::

::: {.notes}
We also see that we can use lapse day and lapse hour to make predictions of the lapse probability in the next hour.  

Not surprisingly, people are more likely to lapse on weekends and during evening hours and the hour level model can use that information to improve its lapse predictions.  

These features likely contribute to the superior performance of the hour model relative to the day and week interval prediction models.  
:::

-----------------------------------------------------------------------------

## Understanding the Models: Next Hour Model

::: {.columns}
:::: {.column width="40%"}

\

- [All EMA items impact lapse probability]{.gray}

\

- [Lapse day and lapse hour are useful]{.gray}

\

- Demographics not particularly important (but limited race/ethnic diversity)
::::

:::: {.column width="60%"}
```{r}
#| label: figs_global_all-3
#| fig-height: 6
#| fig-width: 8

fig_global_hour
```
::::
:::

::: {.notes}
And finally, we see that demographics were not particularly important for predicting lapses. In other words, the frequency of observed lapses did not differ meaningfully by these demographic characteristics.  

This shouldnt be too surprising either, because these demographic characteristics are stable for an individual over time and therefore can't explain changes in lapse probability within an individual over time. 
:::

-----------------------------------------------------------------------------

## Interium Summary and Next Steps

\

- Very strong overall performance
- Temporally precise models for immediate future lapse risk
- EMA risk features are intepretable and sensible

::: {.notes}
So lets pause here for a quick re-cap of where we are so far

- We have models that predict exceptionally well

- These models have a high degree of temporal specificity, even down to hour level resolution

- The risk features from EMA map sensibly onto known lapse risks and we have interventions and supports designed to address many of these risks

So, obviously, we are really excited about the potential capabilities of a recovery monitoring and support system that includes these models to provide personalized continuing care.

- BUT, we still have some very important work to do with respect to several issues that are critical to resolve before we can implement these models effectively and without causing potential harm.
:::

-----------------------------------------------------------------------------

## Next Steps:  Algorithmic Fairness

::: {.notes}
To start, our models have some serious but unfortunately not unexpected problems given what I told you earlier about the some of the demographic limitations of our training data.  

I've already shown you that our models perform exceptionally well when evaluated across the full sample.  However, when we evaluate model performance, it is critical that we look at performance in protected subgroups.  And too often, these analyses are not done or reported.  

Its only very recently that we have begin to take this seriously and we must.  If we hope to use our system to address existing disparities in SUD outcomes then our models must perform well with all groups, regardless of their privilege or the use of these models may exacerbate rather than reduce existing mental healthcare disparities.
:::

-----------------------------------------------------------------------------

## Next Steps: Algorithmic Fairness

::: {.columns}
:::: {.column width="50%"}
```{r}
#| label: fig_race_1
#| fig-height: 6
#| fig-width: 8

fig_race_bar
```
::::

:::: {.column width="50%"}
<!--BLANK-->
::::
:::

::: {.notes}
As one example of this issue, the data we collected to train these models from this first NIAAA grant did not include much racial or ethnic diversity among the participants.   We collected those data at a time when we weren't yet thinking as carefully about issues of representation as we try to do now.
:::

-----------------------------------------------------------------------------

## Next Steps: Algorithmic Fairness

::: {.columns}
:::: {.column width="50%"}
```{r}
#| label: fig_race_2
#| fig-height: 6
#| fig-width: 8

fig_race_bar
```
::::

:::: {.column width="50%"}
```{r}
#| label: figs_fair_race
#| fig-height: 6
#| fig-width: 8

source(here::here("figs/risk/figs_fairema_ci.R"))
fig_fair_race_1
```
::::
:::

::: {.notes}
Given that, we were dismayed but not surprised to find that those models perform substantially worse (with auROCs that are .19 units lower) when predicting lapses for anyone who wasn’t white and non-hispanic.
:::

-------------------------------------------------------------------------------

## Algorithmic Fairness

```{r}
#| label: figs_fairema_ci-2
#| fig-height: 6
#| fig-width: 10 

cowplot::plot_grid(fig_fair_race_1, fig_fair_income_1, fig_fair_sex_1,
                   nrow = 1)
```

::: {.notes}
And these fairness issues were not limited to just race and ethnicity.  We see worse performance for participants with incomes below the poverty line and to a lessor extent for female participants. 

This is obviously unacceptable and we are working now to correct this.
:::

-----------------------------------------------------------------------------

## Next Steps: Algorithmic Fairness

\

- NIDA project recruited ~ 400 patients in recovery from Opioid Use Disorder 
- National sample (size; diversity: demographics, location)
- More variation in stage of recovery (1 – 6 months at start)
- Sensing for 12 months



![](https://github.com/jjcurtin/slide_decks/blob/main/images/risk2_pi_wide.png?raw=true){.absolute bottom=0}

::: {.notes}
For example, we have just recently completed data collection for a NIDA funded project that collected a more racially diverse sample using nationwide recruiting techniques.  

This sample also includes much needed geographic diversity because the factors that predict lapse in urban settings may be different from those that predict lapse in rural settings.

I should also note that in this project, we only administered EMAs once per day to reduce measurement burden given that we tracked participants for up to a full year.
:::

-----------------------------------------------------------------------------

## Next Steps: Algorithmic Fairness

- Excellent performance: auROC ~ 0.94

::: {.notes}

[PAUSE]

We have just begun to train models using EMA features from this new dataset so these next results and data figures should be considered preliminary but we are excited to see that even with only 1 EMA per day, we are now getting the best performance we have seen to date when predicting lapses in the next day.

An auROC of .94
:::

-----------------------------------------------------------------------------

## Next Steps: Algorithmic Fairness

- [Excellent performance: auROC ~ 0.94]{.gray}

```{r}
#| label: figs_fair_risk2_ci_1
#| fig-height: 6
#| fig-width: 10 

source(here::here("figs/risk2/figs_fair_ci.R"))
cowplot::plot_grid(fig_fair_race_2, fig_fair_income_2, fig_fair_sex_2,
                   nrow = 1)
```

::: {.notes}
And more importantly, this next day prediction model appears much fairer with respect to its performance in all three of the subgroups where our original models were deficient.

[PAUSE]

But let me explicitly say that issues related to fairness and the potential to exacerbate health disparities through the use of a sensing and AI based monitoring and support system are much more complicated than what I've had time to present here. 

I’d be happy to dive a bit deeper into this during the discussion period if people are interested to engage more with this.
:::

-----------------------------------------------------------------------------

## Next Steps: Sensing Geolocation and Communcations

::: {.notes}

[PAUSE]

As our monitoring and support system continues to mature, we will also want a richer, broader set of lapse risk features so that we can distinguish better between different situations that require different supports. We can do this by engineering features from our location and communication signals, which tap into different experiences than what we measure by EMA.

And as an added benefit, the use of passive sensing rather than EMA may also lower the patient burden of using these systems long term.

Let's take a look at what we can get from geolocation and communications signals to provide you with some intuition about how we think this will work.
:::

--------------------------------------------------------------------------------

## Next Steps: Sensing Geolocation and Communcations

![](https://github.com/jjcurtin/slide_decks/blob/main/images/john_gps_wide.png?raw=true){.absolute bottom=0 left=0 width="100%"}

::: {.notes}
Here is a wide view of my moment-by-moment location detected by a GPS app over a month when we were first experimenting with this sensing method.  The app recorded the paths that I traveled, with movement by car in green and running in blue.

The red dots indicate places that I stopped to visit for at least a few minutes.

And although not displayed here, the app recorded the days and exact times that I was at each of these locations.

From these data, you can immediately see that I am runner, with long runs leaving from downtown Madison and frequent trail runs on the weekends in the county and state parks to the west and northwest.
:::

-----------------------------------------------------------------------------

## Next Steps: Sensing Geolocation and Communcations

![](https://github.com/jjcurtin/slide_decks/blob/main/images/john_gps_zoom.png?raw=true){.absolute bottom=0 left=0 width="100%"}

::: {.notes}
Zooming in to the Madison isthmus, these data show that I drove my children halfway around the lake each morning to their elementary school.  And from these data we might be able to detect those stressful mornings when getting my young kids dressed and fed didn't go as planned and we were late, sometimes **very late**, to school!

The app recorded my daily running commute through downtown Madison to and from my office.  From this, we can observe my longs days at the office and also those days that I skipped out.

Looking at the red dots indicating the places I visit, the app can detect the restaurants, bars, and coffee shops where I eat, drink and socialize.  We can use public map data to identify these places and make inferences about what I do there.
:::

-----------------------------------------------------------------------------

## ...Imagine my text messages...

![smartphone_uber.png](https://github.com/jjcurtin/lectures/blob/main/images/smartphone_uber.png?raw=true){.absolute top="15%" left="33%" width="33%" height="auto"}\ 

::: {.notes}
In addition to geolocation, we also collected my smartphone communications logs and even the content of my text messages.

And no such luck, I don't plan to show you my actual text messages!

[PAUSE]

But imagine what we could learn about me from the patterns of my communications - Who I was calling, when I made those calls, and even the content of what I sent and received by text message.
:::

-----------------------------------------------------------------------------

## Context is Critical

<!--intentional blank page-->

::: {.notes}
We believe we can improve the predictive strength of these geolocation and communication signals even further by identifying the specific people and places that make us happy or sad or stressed, those that we perceive support our mental health and recovery and those who undermine it.
:::

-----------------------------------------------------------------------------

## Context is Critical

![smartphone_context.png](https://github.com/jjcurtin/lectures/blob/main/images/smartphone_context.png?raw=true){.absolute top="15%" left="33%" width="33%" height="auto"}\ 

::: {.notes}
For example, consider the implications of this brief text message thread between a hypothetical patient and their drinking buddy for what you might predict for the probability that they might lapse back to drinking in the coming hours.   

[PAUSE]

... And how would your prediction change if this wasn’t their drinking buddy but instead, their mom who was a big supporter of their recovery.

This interpersonal context matters!!!
:::

-----------------------------------------------------------------------------

## Context is Critical

<!--intentional blank page-->


::: {.notes}
We gather this contextual information quickly by asking a few key questions about the people and places we interact with frequently over the first couple of months that we record these signals.  And we can identify these frequent contacts and locations directly from these signals.

In our current projects, we target people and places that we interact with at least twice a month or more for more detailed follow-up to gather context.    And it turns out that this really isn’t that burdensome.   Most of us are creatures of habit and if we set a threshold for 2x monthly interactions, we typically only have 10-30 people and places that meet this threshold.   And it’s the same people and places each month so we can build this context up when the person first starts to use the system and after that it only needs to be updated occasionally when we go somewhere new or make a new friend.
:::

-----------------------------------------------------------------------------

## Contextualized Geolocation

\

- [Location type]{.uwred} (e.g., home, home of friend, bar, restaurant, liquor store, work, health care, AA/recovery meeting, gym/fitness center)
- Is [alcohol available]{.uwred} at this location
- Have you [drank alcohol]{.uwred} at this location?
- Is your [experience at this location]{.uwred} generally pleasant, unpleasant, mixed or neutral?
- This location is ([high risk, moderate risk, low risk, no risk]{.uwred}) for my recovery

::: {.notes}

HIGHLIGHT THE CONTEXT INFO WE ARE COLLECTING

NOTE THAT SOME CAN COME FROM PUBLIC DATA
:::

-----------------------------------------------------------------------------

## Contextualized Communications

\

- Have you [drank alcohol]{.uwred} with this person?
- What is their [drinking status]{.uwred} (e.g., drinker, non-drinker)?
- Would you expect them to [drink in your presence]{.uwred}?
- Are they currently [in recovery]{.uwred} from alcohol or other substances?
- Do they [know about your recovery goals]{.uwred} and if so, [are they supportive]{.uwred}?
- Are your [experiences with them]{.uwred} typically pleasant, unpleasant, mixed or neutral?

::: {.notes}
TALK FIRST ABOUT COMMUNICATIONNS CONTEXT

THEN TALK ABOUT PRELIMINARY ANALYSES FROM CLAIRE, COCO, AND KENDRA
:::

-----------------------------------------------------------------------------

## Next Steps: Clinical Uses
  
::: {.notes}
Finally, we need to determine how to use these models for clinical benefit.  And we are just now starting to focus on this goal with a grant that was just funded by NIAAA this past Fall.   

So let me spend a bit of time unpacking how we are thinking about implementing this system for patients.
:::
-----------------------------------------------------------------------------

## Next Steps: Clinical Uses

\

Do [NOT]{.uwred} provide model output to clinicians

- Clinicians are over-burdened
- Not ready for new data streams

::: {.notes}
When we started this work, we believed we were building this system to inform clinicians about their caseload.  

Today's digital therapeutics have clinician dashboards built into them and we, perhaps naively, thought clinicians could use this information to prioritize their resources to patients who had the greatest need.

But as we talked to clinicians, it became very clear that they do not want any more info at this point.  Post-pandemic, they are barely keeping their heads above water and are definitely not ready to add new systems and data streams in place.

However, in contrast, our work with participants suggested that they did see potential value in monitoring their recovery using our monitoring and support system.   So we have pivoted to considering what might be useful to provide directly to them.
:::

-----------------------------------------------------------------------------

## Next Steps: Clinical Uses

::: {.columns}
:::: {.column width="50%"}

\

Do [NOT]{.uwred} predict class labels  (Lapse vs. No-Lapse)

- Iatriogenic effects?
- Information loss
::::

:::: {.column width="50%"}
<!--Blank-->
::::
:::

::: {.notes}
Lets start first with how we should NOT use this system with individuals with SUDs.

We have been focusing on the lapse probabilities that are natively output from our prediction models.   However, its common to use these models to predict formal class labels.  In other words, to specifically predict that a lapse will happen or not.  Basically, a threshold is set, for example, 0.5, and if the probability of a lapse exceeds that threshold the model predicts that a lapse will occur.  Otherwise, it predicts that no lapse will occur

But there are several reasons that we DO NOT want to predict dichotomous class labels.
:::

-----------------------------------------------------------------------------

## Next Steps: Clinical Uses

::: {.columns}
:::: {.column width="50%"}

\

Do [NOT]{.uwred} predict class labels  (Lapse vs. No-Lapse)

- Iatriogenic effects?
- Information loss
::::

:::: {.column width="50%"}
<!--Blank-->
::::
:::

::: {.notes}
To start, there may be concerns about possible iatriogenic effects associated with telling a person that they are going to lapse. Or at least this should be a risk that is carefully considered if we provide these blunt dichotomous predictions to individuals.

Second, these days, I think we have all come to understand that taking scores that are natively quantitative like probabilities are, and artificially dichotomizing them results in substantial loss of information that is potentially valuable.
:::

-----------------------------------------------------------------------------

## Next Steps: Clinical Uses

::: {.columns}
:::: {.column width="50%"}

\

[DO]{.uwred} use lapse probability

- auROCs range from 0.90 - 0.94
::::

:::: {.column width="50%"}
<!-- blank  -->
::::
:::

::: {.notes}
Instead of using the models to predict class labels, we believe that there is potentially high value in using the original lapse probabilities directly output by the model.

I've already shown you that these probabilities can discriminate very well between lapse and no-lapse observations, correctly assigning a higher probability to lapses more than 90% of the time.
:::

-----------------------------------------------------------------------------

## Next Steps: Clinical Uses

::: {.columns}
:::: {.column width="50%"}

\

[DO]{.uwred} use lapse probability

- [auROCs range from 0.90 - 0.94]{.gray}
- Probabilities are calibrated and ordinal
- Provides fine gradations of relative risk for clinical decision-making
::::

:::: {.column width="50%"}
```{r}
#| label: fig_cal
#| fig-height: 6
#| fig-width: 6

fig_cal
```
::::
:::

::: {.notes}
And critically, these probabilities are very well calibrated and at least ordinal in their relationship with the true probability that a lapse will occur.   

On the right, I am showing you a simple calibration plot.  On the x-axis, I've binned predicted lapse probabilities into bin widths of 10 percent and for each of these bins, I display the actual observed probability of lapses for observations in that bin.  

If the probabilities were perfectly calibrated, the bin means would all fall on the dotted line with the bin from 0 - 10 having an observed probability of .05, the bin from 10 - 20 having a probability of .15, and so on.  And this is essentially what we see for our models.

Given this, we believe that the lapse probabilities can provide precise, fine gradations of risk for clinical decision making.
:::

-----------------------------------------------------------------------------

## Next Steps: Personalized Daily Support Recommendations

\

- SHAP values from the NEXT DAY model can identify the most important risk features for a [specific individual]{.uwred} on [each day]{.uwred}
- These features can be used to [personalize]{.uwred} daily support recommendations

::: {.notes}

But we can get much more than just lapse probabilities from these models.

Previously I showed you how we can use global SHAP values to determine which features are important in the aggregate across all people and timepoints.   

We can also use SHAP values to understand which features contributed most strongly to any single prediction for a specific person at a specific moment in time. 

This allows us to understand not only WHEN a lapse might occur but also WHY and therefore potentially how best to intervene.
:::

-----------------------------------------------------------------------------

## Next Steps: Personalized Daily Support Recommendations

::: columns
:::: {.column width="50%"}
```{r}
#| fig-height: 3
#| fig-width: 5

source(here::here("figs/opt/figs_opt_shaps.R"))
fig_shap_ex1
```
::::

:::: {.column width="50%"}
<!--Blank
::::
:::

::: columns
:::: {.column width="50%"}
<!-- Blank-->
::::

:::: {.column width="50%"}
<!-- Blank-->
::::
:::

::: {.notes}
For example, in this first plot,  I am showing you SHAP values for someone who would be predicted to have a high lapse probability on day 30 of their recovery because they have been reporting high craving.  For that person, we could recommend urge surfing techniques or remind them that distracting activities can help get them through short periods of craving that day.
:::

-----------------------------------------------------------------------------

## Next Steps: Personalized Daily Support Recommendations

::: columns
:::: {.column width="50%"}
```{r}
#| fig-height: 3
#| fig-width: 5

fig_shap_ex1
```
::::

:::: {.column width="50%"}
<!--blank-->
::::
:::

::: columns
:::: {.column width="50%"}
```{r}
#| fig-height: 3
#| fig-width: 5

fig_shap_ex2
```
::::

:::: {.column width="50%"}
<!--Blank-->
::::
:::

::: {.notes}
In contrast, a second person might have similarly high lapse probability on day 30 of their recovery, but instead because they have lapsed a few times in recent weeks. They could be encouraged and assisted to complete activities designed to increase their motivation for abstinence. 
:::

-----------------------------------------------------------------------------

## Next Steps: Personalized Daily Support Recommendations

::: columns
:::: {.column width="50%"}
```{r}
#| fig-height: 3
#| fig-width: 5

fig_shap_ex1
```
::::

:::: {.column width="50%"}
<!--Blank-->
::::
:::

::: columns
:::: {.column width="50%"}
```{r}
#| fig-height: 3
#| fig-width: 5

fig_shap_ex2
```
::::

:::: {.column width="50%"}
```{r}
#| fig-height: 3
#| fig-width: 5

fig_shap_ex3
```
::::
:::

::: {.notes}
And at a later point in time, on day 70, that same person may have improved their abstinence motivation but now be at increased risk for a lapse because of a string of recent past and anticipated stressors.   

Now they could be provided with guided stress reduction or relaxation techniques that they could use each day.  

In this way, we can provide personalized recommendations to patients that are tailored to their unique risk profile at that moment in time.
:::

-----------------------------------------------------------------------------

## Next Steps: Personalized Daily Support Recommendations

\

- [SHAP values from the NEXT DAY model can identify the most important risk features for a specific individual on each day]{.gray}
- [These features can be used to [personalize]{.uwred} daily support recommendations]{.gray}
- We can also [eventually learn]{.uwred} which interventions are best for which risk

::: {.notes}
As a starting point, the mapping between between important local risk features and specific interventions or supports can be created using clinical domain expertise. In other words, what would a clinician tell their patient to do in those circumstances. We can simply hard code these clinically derived mappings between risk features and support recommendations in our monitoring and support system.  And this is what we are doing currently.

However, with enough training data, reinforcement learning can also be applied to this problem to allow the model to learn the best intervention to recommend given a set of risk features to reduce subsequent lapse probability.
:::

-----------------------------------------------------------------------------

## Next Steps: Advanced Warning 

::: {.columns}
:::: {.column width="50%"}
- These previous models only predict immediate future - next week, next day, next hour
- People may need advanced warning to put some types of supports into place 
::::

:::: {.column width="50%"}

<!--Blank-->

::::
:::

::: {.notes}

[PAUSE]

Now, you might have noticed that up until this point, I've only talked about predictions for the immediate future - the next week, the next day, or the next hour.  And in these past few examples, I've been talking about using one of those immediate models - the next day model - to provide personalized support recommendations that the patient can implement that next day.

However, for some types of support, people may need some advanced warning to put those supports into place.   For example, if you need to meet with your AA sponsor or get into see your therapist, you will need some lead time to schedule those meetings or appointments.   
:::

-----------------------------------------------------------------------------

## Next Steps: Advanced Warning 

::: {.columns}
:::: {.column width="50%"}
- [These previous models only predict immediate future - next week, next day, next hour]{.gray}
- [People may need advanced warning to put some types of supports into place]{.gray}

\

- We explored lagging the one week model up to two weeks into the future
- Performance drops but still remains good
:::

:::: {.column width="50%"}
```{r}
#| label: figs_lag_ci
#| fig-height: 6
#| fig-width: 6

source(here::here("figs/risk/figs_lag_ci.R"))
fig_lag_ci
```
::::
:::

::: {.notes}
Given this, we have begun to explore various methods for predicting lapse probabilities further into the future.  


As a first step, we took the model which predicted lapses in the next week and lagged it by different periods from one day up to two weeks into the future.   For example, the two week lagged model predicts the probability of a lapse that will occur during a one week period but that period begins two weeks from now.  

And as you can see from the plot on the right, this approach does result in a drop in performance as we move further into the future.  But even with a two week lag, we still have an auROC of .85 which is still potentially clinically useful.

And we are currently exploring other methods for predicting lapse probabilities further into the future that may perform better than this simple lagging approach and I'd be happy to talk more about those during the discussion period if anyone is interested.
:::

-----------------------------------------------------------------------------

## Next Steps: Optimize System Feedback to Patients 

\

- Sensing EMA and geolocation for four months

- Model updated each night for next day
  - Lapse probability predictions
  - Important risk features
  - Risk relevant support recommendations

- Participants receive daily messages varying combinations of these components

- Measure trust, engagement, and clinical outcomes


![](https://github.com/jjcurtin/slide_decks/blob/main/images/opt_pi_wide.png?raw=true){.absolute bottom=0}

::: {.notes}
And that brings us to perhaps the most important next step to implementing our Smart Recovery Monitoring and Support System.

Just because our prediction models perform well, doesn't guarantee that they will provide meaningful clinical benefits.

We need to be able to provide feedback from these models to patients such that they trust the system and its feedback, find it useful, and engage with it over time in a way that improves their recovery.  Questions about what information to provide, how to present it, and when to present it are all critical to the success of this system.

And we were just awarded another grant from the NIAAA to do exactly this.  

In this project, we have embedded a prediction model that uses inputs from both EMA and geolocation within our Smart recovery monitoring and support system. 

Participants will use this system for 4 months.  Each day, the model will 

- make daily lapse probability predictions, 
- identify current personalized lapse risks, 
- and map those risks to behavioral and support recommendations that are specific to each person each day.   

We can then manipulate what information we include in daily messages from the system to participants to increase their trust and engagement with the system as well as formally evaluating its clinical benefits.

Obviously, we are very excited to get started on this project because it will bring us one step closer to providing meaningful support to individuals in recovery.   

Thanks for your time.  I am eager to hear your reactions to all of this and I'd be happy to answer any questions.
:::

-----------------------------------------------------------------------------

## CRediTs

![credits.png](https://github.com/jjcurtin/lectures/blob/main/images/credits_risk1.png?raw=true){.absolute bottom="5%" left="5%" width="80%" height="auto"}\ 

## Acknowledgements (recent projects first){.smaller}

::::: {.columns}

:::: {.column width="48%"}

:::{style="text-align: center;"}

**Co-Investigators **

:::

![](/images/people/gustafson.png){style="margin:0 !important;" width="23%"}

![](/images/people/mohr.png){style="margin:0 !important;" width="23%"}

![](/images/people/kornfield.png){style="margin:0 !important;" width="23%"}

![](/images/people/vanswol.png){style="margin:0 !important;" width="23%"}  

![](/images/people/ammerman.png){style="margin:0 !important;" width="23%"}

![](/images/people/murphy.png){style="margin:0 !important;" width="23%"}

![](/images/people/shah.png){style="margin:0 !important;" width="23%"}

![](/images/people/zhu.png){style="margin:0 !important;" width="23%"}  

![](/images/people/brown.png){style="margin:0 !important;" width="23%"}

![](/images/people/huang.png){style="margin:0 !important;" width="23%"}

![](/images/people/sethares.png){style="margin:0 !important;" width="23%"}

![](/images/people/alagoz){style="margin:0 !important;" width="23%"}

::::

:::: {.column width="24%"}

:::{style="text-align: center;"}

**Graduate Students**

:::

![](/images/people/wyant.png){style="margin:0 !important;" width="47%"}

![](/images/people/punturieri.png){style="margin:0 !important;" width="47%"}

![](/images/people/yu.png){style="margin:0 !important;" width="47%"}

![](/images/people/santana.png){style="margin:0 !important;" width="47%"}

![](/images/people/fronk.png){style="margin:0 !important;" width="47%"}

::::

:::: {.column width="24%"}

:::{style="text-align: center;"}

**Staff**

:::

![](/images/people/wanta.png){style="margin:0 !important;" width="47%"}

![](/images/people/papp.png){style="margin:0 !important;" width="47%"}  

![](/images/people/colmenares.png){style="margin:0 !important;" width="47%"}

![](/images/people/lightheart.png){style="margin:0 !important;" width="47%"}

::::

:::::

## Acknowledgements (alphabetized) {.smaller}

::::: {.columns}

:::: {.column width="48%"}

:::{style="text-align: center;"}

**Co-Investigators **

:::

![](/images/people/alagoz){style="margin:0 !important;" width="23%"}

![](/images/people/ammerman.png){style="margin:0 !important;" width="23%"}

![](/images/people/brown.png){style="margin:0 !important;" width="23%"}

![](/images/people/gustafson.png){style="margin:0 !important;" width="23%"}

![](/images/people/huang.png){style="margin:0 !important;" width="23%"}

![](/images/people/kornfield.png){style="margin:0 !important;" width="23%"}

![](/images/people/mohr.png){style="margin:0 !important;" width="23%"}

![](/images/people/murphy.png){style="margin:0 !important;" width="23%"}

![](/images/people/sethares.png){style="margin:0 !important;" width="23%"}

![](/images/people/shah.png){style="margin:0 !important;" width="23%"}

![](/images/people/vanswol.png){style="margin:0 !important;" width="23%"}

![](/images/people/zhu.png){style="margin:0 !important;" width="23%"}  

::::

:::: {.column width="24%"}

:::{style="text-align: center;"}

**Graduate Students**

:::

![](/images/people/fronk.png){style="margin:0 !important;" width="47%"}

![](/images/people/punturieri.png){style="margin:0 !important;" width="47%"}

![](/images/people/santana.png){style="margin:0 !important;" width="47%"}

![](/images/people/wyant.png){style="margin:0 !important;" width="47%"}

![](/images/people/yu.png){style="margin:0 !important;" width="47%"}

::::

:::: {.column width="24%"}

:::{style="text-align: center;"}

**Staff**

:::

![](/images/people/colmenares.png){style="margin:0 !important;" width="47%"}

![](/images/people/lightheart.png){style="margin:0 !important;" width="47%"}

![](/images/people/papp.png){style="margin:0 !important;" width="47%"}

![](/images/people/wanta.png){style="margin:0 !important;" width="47%"}

::::

:::::
