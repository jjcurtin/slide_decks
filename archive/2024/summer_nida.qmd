We all know that we have a serious problem with treatment access and utilization for individuals with SUD

- Fewer than 1/10 people with an active SUD receive any treatment in any given year
- Large health disparties make these numbers even worse for vulnerable gropus defined by race, ethnicity and geography 
- These numbers are worth still for continuing care following initial treatment even though we know that SUDs often require lifelong management

-----

Unfortunately, our failure to treat is not surprising.  There are many well known barriers to receiving traditional mental healthcare.

- These include problems with access that affect everyone but are particularly limiting for people living in rural communities

- There are problems with availability

- Treatment costs are often prohibitive for those without health insurance 

- and stigma and related issues make traditional treatments for mental illness less acceptable to some patients.  

-----

We believe that digital therapeutics or DTx can play an important role in addressing barriers to care and today's digital therapeutics are already providing meaningful clinical benefits to research participants and patients

BUT, its also important to acknowledge that the digital therapeutics available today are still best considered beta versions relative to their full potential 

Their power comes from easy, 24/7 access to their many supports.  But this is also their Achilles heel. As the patient using these apps, you now have to tackle difficult questions like:

- When should I use them?
- For how long?
- Which of their many supports are best for me?
- And which are best for me **right now**, at this moment in time?

-----

**[--------------CLICK FORWARD-----------------]**

These are essentially precision mental health questions about providing the right supports to the right people at the right time, every time

And we believe digital therapeutics can provide this personalized care if we enhance them with embedded sensing capabilities and machine learning risk prediction models 

-----

[PAUSE]

So how are we approaching this precision mental health challenge?

To start, we have begun to develop risk prediction models that focus both on **predicting** and **explaining** future lapses

Our focus is on future lapses because lapses are 

- Clearly defined and have a temporally precise onset
- They can serve as an early warning sign for relapse
- And for some drugs, even single lapses can result in overdoses and deaths

-----

The inputs to these lapse prediction models come from feature engineering three separate but complementary sets of raw signals that can be sensed easily on any smartphone.  These are

- Ecological momentary assessments
- Geolocation
- Cellular communications meta data and text message content

-----

Our goal is to use features from these powerful signals to develop lapse prediction models with exceptionally high temporal resolution 

- In other words, we aren't looking to simply identify individuals at high risk for lapses 
- Instead we want to know precisely when these lapses will occur so that we can intervene to prevent them 

-----

**[--------------CLICK FORWARD-----------------]**

And we have already demonstrated that we can do this for AUD lapses with features from EMA

- We have developed models to predict future lapses in the next week, the next day, and even the next hour

- And these models perform exceptionally well.  In the top right figure, you can see that all three auROCs are at or above .90, even when predicting lapses in precise one-hour windows

-----

This gives us the first two pieces we need for a precision mental health solution

- it tells us **who** needs support and **when** that support is needed.   

- But we can also apply emerging methods from the field of interpretable AI to these lapse prediction models to begin to understand **why** they are at risk for lapses and therefore **recommend** what supports they may need to prevent that lapse

-----

**[--------------CLICK FORWARD-----------------]**

In the bottom right figure, I am showing you local SHAP values from the next hour risk prediction model.  These SHAP values allow us to know which features contributed most strongly to each individual lapse risk prediction, in other words a prediction for a specific individual at a specific time.

For example, today one DTx user may show a high lapse probability and the model may have assigned that probability because they have been craving a lot recently. For that person, we could recommend urge surfing techniques and provide them support doing it within the DTx. A second person might have similarly high lapse probability but instead because they have lapsed a few times in recent weeks.  They could be encouraged to complete activities designed to increase their motivation for abstinence. A third person might have a **low** probability of lapsing because they have reported many recent positive activities.  No intervention might be needed for this person but they could receive feedback about how their commitment to their well-being was paying off for their recovery.   

-----

As a starting point, the mapping between between important local risk features and specific interventions or supports could be created using clinical domain expertise.  In other words, what would a clinician tell their patient to do in those circumstances.  However, reinforcement learning can also be applied to this problem to allow the model to learn the best intervention to recommend given a set of risk features to reduce subsequent lapse probability. 

-----

As the sensing and recommendation system continues to mature, we will want a richer, broader set of lapse risk features so that we can distinguish better between different situations that require different supports.  We can do this by engineering features from our location and communication signals, which tap into different experiences than what we measure by EMA. 

-----

As we move to providing feedback to DTx users about when and how to use their DTx, we need to optimize this feedback so that people trust and follow these AI generated recommendations.  We need to think carefully and systematically evaluate what sources of information from our models we can provide to users to increase trust

- Do we share their current lapse probability and recent past trends in these probabilities?
- Do we share what we've learned about their risk features from sensing?  This might increase trust AND also help them improve their own self-monitoring skills.

-----

And, of course, once the sensing and recommendation system is optimized, we need to evaluate its clinical benefits

As part of the evaluation process, issues of algorithmic bias and fairness immediately become paramount.  DTx have the potential to address existing serious disparities in treatment access and outcomes but if our algorithms perform less well for vulnerable groups, their use might exacerbate rather than reduce these mental healthcare disparities.

-----

**[--------------CLICK FORWARD-----------------]**

Continued quality intervention and support development is also critical because if we are going to personalize support we need to have robust content in place to recommend to patients depending on their specific risk factors and needs at any moment in time.

- My colleagues and I are well-positioned as clinical psychologists with expertise in SUD treatment to do further module and support development

- And there are attractive synergies at UW with Richie Davidson's Center for Healthy Minds, which will allow us to capitalize on intervention development in the mindfulness space including MBSR and Mindfulness based relapse prevention

-----

There are also possibilities to begin to marshall benefits from large language models within DTx

- In the near term, if we want people to trust the support recommendations and other feedback from our risk models, there is evidence that AIs are more trusted when they are more anthropomorphic and using LLMs for the support recommendations may be an easy first step to explore their value.


- There are also opportunities to use LLMs with DTx users to practice skills that might be trained within the DTx.  For example, users could interactively practice drink refusal skills, or practice prosocial skills in advance of an anticipated difficult and stressful conversation with a spouse, colleague, or boss

-----

And to close, I want to make one more point. One of the exciting and attractive aspects about working in the DTx space is that what we learn is easy to port from app to app and platform to platform

- Our sensing can be done on any smartphone. 
- The algorithms and feedback are automated and portable. 
- And the interventions are also easily encapsulated and transferred across apps in an iterative process as we collaboratively advance toward reducing barriers and improving outcomes

Thank you!