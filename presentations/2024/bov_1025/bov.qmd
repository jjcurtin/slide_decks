---
title: 'A "Smart" Recovery Monitoring and Support System for SUD Continuing Care'
author: "John J. Curtin, Ph.D."
institute: "University of Wisconsin-Madison"
date: October 25, 2024
format: 
  revealjs:
    scrollable: false 
    css: bov.css
    slide-number: true 
    multiplex: true
title-slide-attributes:
  data-background-image: https://github.com/jjcurtin/lectures/blob/main/images/smartphone_know_you.png?raw=true
  data-background-size: 35%
  data-background-repeat: no
  data-background-position: left 10% bottom 10%
include-after: |
  <script type="text/javascript">
    Reveal.on('ready', event => {
      if (event.indexh === 0) {
        document.querySelector("div.has-logo > img.slide-logo").style.display = "block";
        document.querySelector("div.has-logo > img.slide-logo").style.display = "block";
        document.querySelector("div.has-logo > img.slide-logo").style.display = "none";
        Reveal.configure({ slideNumber: null });
        Reveal.configure({ slideNumber: 'c' });
editor_options: 
  chunk_output_type: console
---

::: {.notes}
About a decade ago I was approaching the middle of my career.  I'd been at the UW for 15 years and had developed a successful basic clinical science research program as a psychophysiologist running experiments to understand the effects of drugs and drug withdrawal on stress.  The work was intellectually stimulating, we were publishing it in good outlets, and we were getting grants, but my heart was increasingly not in it.  
:::

-----------------------------------------------------------------------------

::: {.notes}
I'd become a clinical psychologist to help people struggling with alcohol and other SUDs.  

- My paternal grandmother died of complications secondary to alcoholism. 

- My dad has struggled with his use of alcohol for his entire adult life. For periods of time, he regulated his use well but at other times he lost control and it affected all of us.

- My cousin, Stephen, has a severe substance use disorder and has been incarcerated several times for drug related offenses.  He has had periods of stability but they have always ended in another relapse.  My Aunt Cathy and Stephen's brother, Colin, had reached out to me on numerous occasions to ask what could be done to help Stephen.  And it was those conversations that really got me thinking about how I could re-direct my research program to help people like Stephen and my dad and my grandmother.  
:::

-----------------------------------------------------------------------------

## A Smart Recovery Monitoring and Support System

![](https://github.com/jjcurtin/slide_decks/blob/main/images/gustafson.jpeg?raw=true){.absolute bottom=0 right=50 width=30%}

::: {.notes}
It was around that time that Dave Gustafson reached out to me.  Dave directs a center on campus that develops digital therapeutics for substance use disorders.  These are essentially smartphone apps that provide ongoing continuing care for patients during their recovery.  He had just completed a large randomized controlled trial demonstrating that his app meaningfully decreased heavy drinking days and increased abstinence rates over the first year of recovery. 

However, he also noticed many of the people who had relapsed hadn't used the app in the days leading up to that relapse.  And others who had relapsed hadn't used the specific supports in the app that he would have thought would be most effective for them.
:::

-----------------------------------------------------------------------------

## A Smart Recovery Monitoring and Support System

\
\

> “Could you predict not only [who]{style="color: blue;"} might be at greatest risk for relapse … <br>
 … but precisely [when]{style="color: blue;"} that relapse might occur … <br>
 … and [how best to intervene]{style="color: blue;"} to prevent it?"
 
 \
 \
 
![](https://github.com/jjcurtin/slide_decks/blob/main/images/gustafson.jpeg?raw=true){.absolute bottom=0 right=50 width=30%}

::: {.notes}
Dave knew that we were exploring the factors that motivated alcohol and other drug use and he asked us a simple question: 

"Could you predict not only who might be at greatest risk for relapse but precisely when that relapse might occur and how best to intervene to prevent it"


... because if we could develop a system to do this, he could embed it into his app to guide people to the most effective supports at the most critical moments in their recovery.  
:::

-----------------------------------------------------------------------------

## A Smart Recovery Monitoring and Support System

- Precision mental health requires us to provide the [right treatments]{style="color: blue;"} and supports to the [right people]{style="color: blue;"} at the [right time]{style="color: blue;"}, [every time]{style="color: blue;"}

\

- Continuing care for substance use disorders requires [long-term monitoring]{style="color: blue;"} and [ongoing lifestyle adjustments and support]{style="color: blue;"} to prevent relapse

::: {.notes}
These questions that Dave was asking are at the heart of what we now call precision mental health.  How can we provide the **right interventions and supports** to the **right people** at the **right time**, **every time**

And this focus on the **right time** is particularly important for recovery from substance use disorders.  Substance use disorders are chronic relapsing conditions and therefore successful recovery requires lifelong monitoring and support to prevent relapse.  

And, critically, the optimal supports for any specific individual can change month to month, day to day, and even from moment to moment.
:::

-----------------------------------------------------------------------------

## A Smart Recovery Monitoring and Support System

- [Precision mental health requires us to provide the right treatments and supports to the right people at the right time, every time]{style="color:gray;"}

\

- [Continuing care for substance use disorders requires long-term monitoring and ongoing lifestyle adjustments and support to prevent relapse]{style="color:gray;"}

\

- A "Smart" Recovery Monitoring and Support System can provide temporally precise, dynamic, personalized continuing care by combining:
  - Sensing
  - Artificial Intelligence/Machine learning

::: {.notes}
But we believed that we could harness and combine several technologies that were emerging at that time to address this challenge.  

Specifically, we thought that we could use personal sensing and artificial intelligence algorithms to develop a smart recovery monitoring and support system that could both predict lapses before they occurred and provide personalized support and recommendations to patients about how to prevent those lapses from occurring.

And what I'd like to do today with my remaining time is tell you a bit about how we are doing this, what we have learned so far, and where we are going next with this system.
:::

-----------------------------------------------------------------------------

## Personal Sensing

Personal sensing collects information from smartphones to identify a person's thoughts, feelings, behaviors, and context.

\

Sensing allows for "real-world" measurement that

- Can be sustained for long periods
- Has very high temporal granularity 

::: {.notes}
First of all, lets talk briefly about the inputs to our system that we collect through personal sensing.  

Personal sensing is just a fancy term for methods that allow us to do real-world measurement of people's thoughts, feelings, behaviors, and context.  

These methods allow us to feasibly collect these inputs over very long periods of time from months to even years.

and we can collect these inputs with very high temporal granularity, at least several times per day and in some instances continuously
:::

-----------------------------------------------------------------------------

## Personal Sensing

[Personal sensing collects information from smartphones to identify a person's thoughts, feelings, behaviors, and context.]{style="color:gray;"}

\

[Sensing allows for "real-world" measurement that]{style="color:gray;"}

- [Can be sustained for long periods]{style="color:gray;"}
- [Has very high temporal granularity]{style="color:gray;"} 

\

We focus on 

- Ecological Momentary Assessment
- Geolocation
- Smartphone Communications (calls and texts)

::: {.notes}
At this point, we have worked extensively with a sensing method called ecological momentary assessment 

but I will also tell you about how we are expanding our sensing methods to include geolocation and smartphone communications data.
:::

-----------------------------------------------------------------------------

## Lapse Prediction for AUD

- 151 individuals with moderate to severe AUD

- Early in recovery (1-8 weeks)

- Committed to abstinence throughout study

- Followed with sensing for up to 3 months
  - Ecological Momentary Assessment
  - Geolocation
  - Smartphone Communications

\

![](https://github.com/jjcurtin/slide_decks/blob/main/images/risk1_pi_wide.png?raw=true){.absolute bottom=0}

::: {.notes}
As the first step toward developing this system, in 2016 we were awarded a large grant from the National Institute on Alcohol Abuse and Alcoholism to recruit a sample of individuals in early recovery from moderate to severe AUD.

We followed these individuals for up to three months, using our three sensing methods and also recording any lapses back to alcohol use.
:::

-----------------------------------------------------------------------------

## Ecological Momentary Assessments (EMA)

- Current/Recent Experiences
  - Craving
  - Affect
  - Recent past alcohol use
  - Recent risky situations
  - Recent stressful events
  - Recent pleasant event

\

- Future Expectations
  - Risky situations
  - Stressful events
  - Abstinence Confidence

![](https://github.com/jjcurtin/slide_decks/blob/main/images/ema_hand.png?raw=true){.absolute bottom=0 right=50 width=45%}

::: {.notes}
The first machine learning prediction models we developed used features from ecological momentary assessment or EMAs from these individuals so let me tell you a bit more about this method.

These EMAs are brief surveys that participants completed on their smartphones.  They take 20-30 seconds to complete and we collected them several times per day.

Participants used these EMAs to report on their current and recent past experiences, such as their craving, affect, and recent alcohol use.  They also report any recent past risky situations, stressful events, and pleasant events.  And they let us know if they expected any future risky situations and stressful events in the coming week and their confidence that they could remain abstinent.
:::

-----------------------------------------------------------------------------

## Model Predictions 

- Predict hour-by-hour probability of [future lapse]{style="color: blue;"}

\

- Lapse window widths
  - Next week 
  - Next day
  - Next hour 

::: {.notes}
For our purposes today I wont dive deep into the machine learning methods but let me highlight a few high level details 

We used features from these EMAs to make predictions about the hour-by-hour probability of a future lapse.  
We developed separate models for three future lapse windows – lapses in the next week, lapses in the next day, and lapses in the next hour.  
:::

-----------------------------------------------------------------------------

## Model Predictions 

- Predict hour-by-hour probability of [future lapse]{style="color: blue;"}

\

- Lapse window widths
  - Next week 
  - Next day
  - Next hour 

::: {.notes}
For example, if I was in recovery from an AUD, I could use these models to generate the probability that I would lapse after this symposium ends at 5 pm. One model would generate the probability I would lapse at some point between 5 pm today and 5 pm next Friday, the second would predict the probability that I would lapse between 5 pm today and 5 pm tomorrow and the third and most temporally precise model would provide the probability that I would lapse in the next hour, between 5pm today and 6pm today.  

And of course, all of the models would only use data collected prior to 5 pm today so that they are “predicting”, in the full sense of the word, into the future and not just demonstrating an association.
:::

-----------------------------------------------------------------------------

## Model Performance

The Area under the Receiver Operating Characteristic Curve (auROC) indicates the probability that any true lapse is scored higher than any true no-lapse by the model

- Random performance:  auROC = 0.5 
- Perfect performance: auROC = 1.0 


:::::{.callout-tip icon=false}
## Rules of thumb for auROC 
.70 - .80 is considered fair  
.80 - .90 is considered good  
\> .90 is considered excellent  
:::::

::: {.notes}
Now, obviously, I wouldn't be standing here telling you about this system if it didnt perform well, but let me take one more to describe how we evaluate these models so that you can understand just how well they do perform.



UPDATE TO DESCRIBE ACCURACY FIRST BUT THEN auROC

So the range of auROCs is approximately .5 - 1.0 

but the auROC also has an intuitive interpretation that I want you to understand.  

Its value represents the probability that any randomly selected positive observation, in our case, a lapse, will be assigned a higher probability score than a randomly selected negative observation where no lapse occurs.

So, for example, that random classifier would only have a 50% chance of predicting a higher risk score for any specific lapse vs. a no-lapse period.  And conversely, the perfect classifier would have a 100% chance of scoring that lapse event higher than a no-lapse event.  



[PAUSE]

:::

-----------------------------------------------------------------------------

## Model Performance: Excellent auROCs

::: {.columns}
:::: {.column width="50%"}
```{r}
#| label: figs_auroc_ci
#| fig-height: 5
#| fig-width: 5

source(here::here("figs/risk/figs_ema_probability.R"))
fig_auroc_ci
```
::::

::::

<!-- Blank-->

:::: {.column width="50%"}
:::

::: {.notes}
UPDATE TO DESCRIBE ACCURACY FIRST BUT THEN auROC

So the range of auROCs is approximately .5 - 1.0 

but the auROC also has an intuitive interpretation that I want you to understand.  

Its value represents the probability that any randomly selected positive observation, in our case, a lapse, will be assigned a higher probability score than a randomly selected negative observation where no lapse occurs.

So, for example, that random classifier would only have a 50% chance of predicting a higher risk score for any specific lapse vs. a no-lapse period.  And conversely, the perfect classifier would have a 100% chance of scoring that lapse event higher than a no-lapse event.  


[PAUSE]

And to be clear, we believe all three of these models to have clinically implementable levels of performance such that we can make meaningful decisions about the probability of a future lapse for individual participants at specfic moments or windows in time.
:::

-----------------------------------------------------------------------------

## Model Performance: Well Calibrated

::: {.columns}
:::: {.column width="50%"}
```{r}
#| label: figs_auroc_ci-2
#| fig-height: 5
#| fig-width: 5

fig_auroc_ci
```
::::

:::: {.column width="50%"}
```{r}
#| label: fig_cal
#| fig-height: 6
#| fig-width: 6

fig_cal
```
::::
:::

::: {.notes}
And critically, these probabilities are very well calibrated and at least ordinal in their relationship with the true probability that a lapse will occur.   

On the right, I am showing you a simple calibration plot.  On the x-axis, I've binned predicted lapse probabilities into bin widths of 10 percent and for each of these bins, I display the actual observed probability of lapses for observations in that bin.  

If the probabilities were perfectly calibrated, the bin means would all fall on the dotted line with the bin from 0 - 10 having an observed probability of .05, the bin from 10 - 20 having a probability of .15, and so on.  And this is essentially what we see for our models.

Given this, we believe that the lapse probabilities can provide precise, fine gradations of risk for clinical decision making.

And to be clear, we believe all three of these models to have clinically implementable levels of performance such that we can make meaningful decisions about the probability of a future lapse for individual participants at specfic moments or windows in time.
:::

-----------------------------------------------------------------------------

## Beyond Prediction: Personalized Recommendations 

::: columns

::: {.column width="50%"}
```{r}
#| label: figs_tr2
#| fig-height: 3
#| fig-width: 5

source(here::here("figs/opt/figs_opt_shaps.R"))
fig_shap_ex1
```
:::

::: {.column width="50%"}

:::
:::

::: columns

::: {.column width="50%"}
```{r}
#| label: figs_bl2
#| fig-height: 3
#| fig-width: 5

fig_shap_ex1
```
:::

::: {.column width="50%"}
```{r}
#| label: figs_br2
#| fig-height: 3
#| fig-width: 5

fig_shap_ex1
```
:::
:::

::: {.notes}

We can get more than just the days when lapses are probable from these models.

We can also begin to use tools from the emerging field of interpretable AI to understand WHY they may occur

- For example, today one DTx user may show a high lapse probability and the model may have assigned that probability because they have been craving a lot recently. For that person, we could recommend urge surfing techniques and provide them support doing it within the DTx. 

- A second person might have similarly high lapse probability but instead because they have lapsed a few times in recent weeks. They could be encouraged to complete activities designed to increase their motivation for abstinence. 

- That same person might later have a low probability of lapsing because they have reported many recent positive activities. No intervention might be needed for this person but they could receive feedback about how their commitment to their well-being was paying off for their recovery.
:::

-----------------------------------------------------------------------------

## Algorithmic Fairness

::: {.columns}
:::: {.column width="35%"}
::::

:::: {.column width="65%"}
::::
:::

::: {.notes}
[PAUSE]

But, not surprisingly given what I told you earlier about the characteristics of our training data, there is important bad news to share as well.

When we evaluate model performance, it is critical that we look at performance in protected groups.  And too often, these analyses are not done or reported.  

Its only very recently that we have begin to take this seriously and we must.  If we hope to use our system to address existing dispartities in SUD outcomes then our models must perform well with all groups, regardless of their privilege or the use of these models may exacerbate rather than reduce existing mental healthcare disparities.
:::

-----------------------------------------------------------------------------

## Algorithmic Fairness

::: {.columns}
:::: {.column width="35%"}
- Substantially poorer performance if not white/non-hispanic
::::

:::: {.column width="65%"}
```{r}
#| label: figs_fairema_ci
#| fig-height: 6
#| fig-width: 8

source(here::here("figs/risk/figs_fairema_ci.R"))
cowplot::plot_grid(fig_race, NULL, NULL, NULL)
```

::::
:::

::: {.notes}
[PAUSE]

And our models have some serious but unfortunately not unexpected problems.

On the right, these are preliminary analyses looking at performance across a variety of binary groups defined by priviledge with respect to SUD treatment access and/or outcomes.  

From these analyses, it is clear that our models perform substantially worse when predicing lapse for anyone who isnt white and non-hispanic.  And this was expected given the lack of racial and ethinic diversity in the sample.
:::

-----------------------------------------------------------------------------

## Algorithmic Fairness

::: {.columns}
:::: {.column width="35%"}
- [Substantially poorer performance if not white/non-hispanic]{style="color: gray;"}

\

- Meaningfully poorer performance for other less priviledged groups

\

- Not just due to under-representation in training data
::::

:::: {.column width="65%"}
```{r}
#| label: figs_fairema_ci-2
#| fig-height: 6
#| fig-width: 8

source(here::here("figs/risk/figs_fairema_ci.R"))
cowplot::plot_grid(fig_race, fig_income, fig_sex, fig_age)
```

::::
:::

::: {.notes}
UPDATE TO ADD SOLUTIONS?



However, there are also some, though smaller, performance issues for other less privileged groups, even when we had reasonable diversity regarding those characteristics in the sample.  And this highlights other sources of potential bias. 

For example, when selecting which EMA questions to ask participants, we based this on domain expertise from decades of research on the risk factors for lapses.  However, that research was done with predominately white, predominately male participants who often had other privileges that allowed for them to participate in research.  Given this, it may not be surprising that when we use this literature to select EMA items to measure, we may fail to include items that might tap lapse risk for people who are not white men.

I'll come back to this later when talking about our NIDA project and next steps and I hope we can discuss this too during the question period.
:::

-----------------------------------------------------------------------------
 
## NIDA Project: A Larger, More Diverse Sample 

- Recruiting ~ 300 patients in recovery from Opioid Use Disorder 
- National sample (size; diversity: demographics, location)
- More variation in stage of recovery (1 – 6 months at start)
- 12 months of monitoring
- Closer to real implementation methods


![](https://github.com/jjcurtin/slide_decks/blob/main/images/risk2_pi_wide.png?raw=true){.absolute bottom=0}

::: {.notes}
With respect to the diversity of the training data, we are now collecting data for a NIDA funded project where we are specifically recruiting for racial, ethnic, and geographic diversity across the entire United States.

We are also recruiting for people at different stages in their recovery and following them for a longer period of time – up to 12 months.  We are scheduled to complete data collection for this project in December of this year.
:::

-----------------------------------------------------------------------------

## Sensing Geolocation and Communcations

- Increase performance overall and in subgroups (more fair?)
- Lower sensing burden
- More (distinct) risk features for intervention recommendations!

::: {.notes}
Second, as our monitoring and support system continues to mature, we will want a richer, broader set of lapse risk features so that we can distinguish better between different situations that require different supports. We can do this by engineering features from our location and communication signals, which tap into different experiences than what we measure by EMA.

And as an added benefit, the use of passive sensing rather than EMA may also lower the patient burden of using these systems long term.

Let's take a look at what we can get from geolocation and communications signals to provide you with some intuition about how we think this will work.
:::

-----------------------------------------------------------------------------

## {#gps_detection_1 data-menu-title="GPS detection, wide view" background-image="https://dionysus.psych.wisc.edu/present/john_gps_wide.png" background-size="100%" background-position="bottom" background-repeat="none"}


::: {.notes}
Here is a wide view of my moment-by-moment location detected by a GPS app over a month when we were first experimenting with this sensing method.  The app recorded the paths that I traveled, with movement by car in green and running in blue.

The red dots indicate places that I stopped to visit for at least a few minutes.

And although not displayed here, the app recorded the days and exact times that I was at each of these locations.

From these data, you can immediately see that I am runner, with long runs leaving from downtown Madison and frequent trail runs on the weekends in the county and state parks to the west and northwest.
:::

-----------------------------------------------------------------------------

## {#gps_detection_2 data-menu-title="GPS detection, zoomed" background-image="https://dionysus.psych.wisc.edu/present/john_gps_zoom.png" background-size="100%" background-position="bottom" background-repeat="none"}


::: {.notes}
Zooming in to the Madison isthmus, these data show that I drove my children halfway around the lake each morning to their elementary school.  And from these data we might be able to detect those stressful mornings when getting my young kids dressed and fed didn't go as planned and we were late, sometimes **very late**, to school!

The app recorded my daily running commute through downtown Madison to and from my office.  From this, we can observe my longs days at the office and also those days that I skipped out.

Looking at the red dots indicating the places I visit, the app can detect the restaurants, bars, and coffee shops where I eat, drink and socialize.  We can use public map data to identify these places and make inferences about what I do there.
:::

-----------------------------------------------------------------------------

## ...Imagine my text messages...

![smartphone_uber.png](https://github.com/jjcurtin/lectures/blob/main/images/smartphone_uber.png?raw=true){.absolute top="15%" width="50%" height="auto"}\ 

::: {.notes}
In addition to geolocation, we also collected my smartphone communications logs and even the content of my text messages.

And no such luck, I don't plan to show you my actual text messages!

But imagine what we could learn about me from the patterns of my communications - Who I was calling, when I made those calls, and even the content of what I sent and received by text message.
:::

-----------------------------------------------------------------------------

## Context is Critical

<!--intentional blank page-->

::: {.notes}
We believe we can improve the predictive strength of these geolocation and communication signals even further by identifying the specific people and places that make us happy or sad or stressed, those that we perceive support our mental health and recovery and those who undermine it.

we gather this contextual information quickly by asking a few key questions about the people and places we interact with frequently over the first couple of months that we record these signals.  and we can identify these frequent contacts and locations directly from these signals.
:::

-----------------------------------------------------------------------------

## Optimize System Support Messages

- How to increase engagement, trust, utility, and benefits?
- Daily support messages from Next Day model based on EMA and and geolocation features

\

- Factorially manipulate (between subjects) four components of support message 
  - Lapse probability for that day
  - Recent trends in lapse probability 
  - Locally important features for that day
  - A risk relevant recommendation

\

- Measure engagement, trust, utility, and clinical outcomes

![](https://github.com/jjcurtin/slide_decks/blob/main/images/opt_pi_wide.png?raw=true){.absolute bottom=0}

::: {.notes}

FREE TALK

:::
-----------------------------------------------------------------------------

## Participant Characteristics


::: {.notes}
Let me begin by giving you a sense of the characteristics of the sample we recruited and will use to train the models for our system.

To start, this is a sample of individuals with a moderate to severe presentation of alcohol use disorder based on their symptom counts.  They were all people who were experiencing very substantial problems in their lives due to their alcohol use.
:::

-----------------------------------------------------------------------------

## Participant Characteristics

```{r}
#| label: figs_ema_demographics
#| fig-height: 6
#| fig-width: 10

source(here::here("figs/risk/figs_ema_demographics.R"))
cowplot::plot_grid(fig_age, fig_sex, fig_income, fig_ms, fig_educ, fig_race, nrow = 2, ncol = 3)
```

::: {.notes}

We had reasonable diversity across many participant characteristics including age, sex at birth, martial status, education, and income

However, given the methods we used for recruiting, we have very little racial and ethnic diversity in the sample.  The sample is predominately white and non-Hispanic.

I'll return to this later both when we evaluate issues of algorithmic fairness and when I talk about another, larger NIDA funded project where we are correcting this issue of racial and ethnic representation in our models.
:::

-----------------------------------------------------------------------------