---
title: 'A "Smart" Recovery Monitoring and Support System for SUD Continuing Care'
author: "John J. Curtin, Ph.D."
institute: "University of Wisconsin-Madison"
date: October 25, 2024
format: 
  revealjs:
    scrollable: false 
    css: bov.css
    slide-number: true 
title-slide-attributes:
  data-background-image: https://github.com/jjcurtin/lectures/blob/main/images/smartphone_know_you.png?raw=true
  data-background-size: 35%
  data-background-repeat: no
  data-background-position: left 10% bottom 10%
include-after: |
  <script type="text/javascript">
    Reveal.on('ready', event => {
      if (event.indexh === 0) {
        document.querySelector("div.has-logo > img.slide-logo").style.display = "block";
        document.querySelector("div.has-logo > img.slide-logo").style.display = "block";
        document.querySelector("div.has-logo > img.slide-logo").style.display = "none";
        Reveal.configure({ slideNumber: null });
        Reveal.configure({ slideNumber: 'c' });
editor_options: 
  chunk_output_type: console
---

::: {.notes}
About a decade ago I was approaching the middle of my career.  I'd been at the UW for 15 years and had developed a successful basic clinical science research program as a psychophysiologist running experiments to understand the effects of drugs and drug withdrawal on stress.  The work was intellectually stimulating, we were publishing it in good outlets, and we were getting grants, but my heart was increasingly not in it.  
:::

-----------------------------------------------------------------------------

::: {.notes}
I'd become a clinical psychologist to help people struggling with alcohol and other SUDs.  

- My paternal grandmother died of complications secondary to alcoholism. 

- My dad has struggled with his use of alcohol for his entire adult life. For periods of time, he regulated his use well but at other times he lost control and it affected all of us.

- My cousin, Stephen, has a severe substance use disorder and has been incarcerated several times for drug related offenses.  He has had periods of stability but they have always ended in another relapse.  My Aunt Cathy and Stephen's brother, Colin, had reached out to me on numerous occasions to ask what could be done to help Stephen.  And it was these conversations that really got me thinking about how I could re-direct my research program to help people like Stephen and my dad and my grandmother.  
:::

-----------------------------------------------------------------------------

## A Smart Recovery Monitoring and Support System

![](https://github.com/jjcurtin/slide_decks/blob/main/images/gustafson.jpeg?raw=true){.absolute bottom=0 right=50 width=30%}

::: {.notes}
It was around this time that Dave Gustafson reached out to me.  Dave directs a center on campus that develops digital therapeutics for substance use disorders.  These are essentially smartphone apps that provide ongoing continuing care for patients during their recovery.  He had just completed a large randomized controlled trial demonstrating that his app meaningfully decreased heavy drinking days and increased abstinence rates over the first year of recovery following the completion of an inpatient treatment program.

However, he also noticed many of the people who had relapsed hadn't used the app in the days leading up to that relapse.  And others who had relapsed hadn't used the specific supports in the app that he would have thought would be most effective for them.
:::

-----------------------------------------------------------------------------

## A Smart Recovery Monitoring and Support System

\
\

> “Could you predict not only [who]{style="color: blue;"} might be at greatest risk for relapse … <br>
 … but precisely [when]{style="color: blue;"} that relapse might occur … <br>
 … and how [best to intervene]{style="color: blue;"} to prevent it?"
 
 \
 \
 
![](https://github.com/jjcurtin/slide_decks/blob/main/images/gustafson.jpeg?raw=true){.absolute bottom=0 right=50 width=30%}

::: {.notes}
Dave knew that we were exploring the factors that motivated alcohol and other drug use and he asked us a simple question: 

"Could you predict not only who might be at greatest risk for relapse but precisely when that relapse might occur and how best to intervene to prevent it"


... because if we could develop a system to do this, he could embed it into his app to guide people to the most effective supports at the most critical moments in their recovery.  
:::

-----------------------------------------------------------------------------

## A Smart Recovery Monitoring and Support System

- Precision mental health requires us to provide the [right treatments]{style="color: blue;"} and supports to the [right people]{style="color: blue;"} at the [right time]{style="color: blue;"}, [every time]{style="color: blue;"}

\

- Continuing care for substance use disorders requires [long-term monitoring]{style="color: blue;"} and [ongoing lifestyle adjustments and support]{style="color: blue;"} to prevent relapse

::: {.notes}
These questions that Dave was asking are at the heart of what we call precision mental health.  How can we provide the **right interventions and supports** to the **right people** at the **right time**, **every time**

But these questions reflect a complex form of precision mental health.  Typically, precision mental health and the broader field of precision medicine have focused on identifying and delivering a single optimal treatment for each person.  But recovery from substance use disorders is a lifelong process.  It isn't sufficient to just select the right medication for each person to reduce craving at the start of treatment or to select their best option among several available empirically supported psycho-social intervention.   

Successful recovery requires ongoing monitoring and support to prevent relapse.  And the optimal supports for an individual can change month to month, day to day, and even from moment to moment.
:::

-----------------------------------------------------------------------------

## A Smart Recovery Monitoring and Support System

- [Precision mental health requires us to provide the right treatments and supports to the right people at the right time, every time]{style="color:gray;"}

\

- [Continuing care for substance use disorders requires long-term monitoring and ongoing lifestyle adjustments and support to prevent relapse]{style="color:gray;"}

\

- A Smart Recovery Monitoring and Support System can provide temporally precise, dynamic, personalized continuing care guidance by combining
  - Sensing
  - AI/Machine learning

::: {.notes}
And it goes without saying that this is hard and it is why lapses and relapse are so common for so many people in recovery.

But we believed that we could harness and combine several technologies that were emerging at that time to address this challenge.  Specifically, we thought that we could use personal sensing and machine learning to develop a smart recovery monitoring and support system that could provide personalized support and recommendations to patients either within a digital therapeutic or as a stand alone support system. 


ADD IDEA THAT THE MODEL WILL PREDICT LAPSE HERE
:::

-----------------------------------------------------------------------------

## Personal Sensing

Personal sensing collects raw data streams from sensors in everyday devices to identify a person's thoughts, feelings, behaviors, and context.

- "Real-world" measurement
- Longitudinal
- High temporal granularity 
- Feasible/acceptable for long term use

::: {.notes}
The next logical set of questions surround the model inputs.   

What will we use as inputs or risk features in these models to predict lapses? And how will we measure the raw signals associated with these risk features?

We believe that personal sensing will play a big role here.  And when I talk about sensing, I am talking about a measurement strategy that allows for in vivo measurement within the context of an individual's day-to-day life.   

It must be longitudinal but also with high temporal granularity so that we have the temporal precision to intervene during days and even potentially moments of heightened risk

And it must be acceptable to people for long term use because we know that SUDs are chronic, relapsing disorders that require lifetime management and continuing care.


There are also some practical requirements.  

If we are going to make the sensing and and prediction system widely available, then the measurement must be feasible, consistent, and stable across common equipment that most people own.  

From our perspective, this limits us to smartphones with the major operating systems


Given these sensing requirements, we are focusing the majority of our effort at this point on feature engineering with three separate but complementary sets of raw signals that can be sensed easily on any smartphone. These are

- Ecological momentary assessments
- Geolocation
- Cellular communications meta data and text message content

Our goal is to use features from these powerful signals to develop lapse prediction models with exceptionally high temporal resolution.  In other words, we aren’t looking to simply identify individuals at high risk for lapses.  Instead we want to know precisely when these lapses will occur so that we can intervene to prevent them
:::

-----------------------------------------------------------------------------

## Personal Sensing

Personal sensing collects raw data streams from sensors in everyday devices to identify a person's thoughts, feelings, behaviors, and context.

- "Real-world" measurement
- Longitudinal
- High temporal granularity 
- Feasible/acceptable for long term use

We focus on

- Ecological Momentary Assessments (EMA)
- Geolocation
- Smartphone Communications

::: {.notes}
The next logical set of questions surround the model inputs.   

What will we use as inputs or risk features in these models to predict lapses? And how will we measure the raw signals associated with these risk features?

We believe that personal sensing will play a big role here.  And when I talk about sensing, I am talking about a measurement strategy that allows for in vivo measurement within the context of an individual's day-to-day life.   

It must be longitudinal but also with high temporal granularity so that we have the temporal precision to intervene during days and even potentially moments of heightened risk

And it must be acceptable to people for long term use because we know that SUDs are chronic, relapsing disorders that require lifetime management and continuing care.


There are also some practical requirements.  

If we are going to make the sensing and and prediction system widely available, then the measurement must be feasible, consistent, and stable across common equipment that most people own.  

From our perspective, this limits us to smartphones with the major operating systems


Given these sensing requirements, we are focusing the majority of our effort at this point on feature engineering with three separate but complementary sets of raw signals that can be sensed easily on any smartphone. These are

- Ecological momentary assessments
- Geolocation
- Cellular communications meta data and text message content

Our goal is to use features from these powerful signals to develop lapse prediction models with exceptionally high temporal resolution.  In other words, we aren’t looking to simply identify individuals at high risk for lapses.  Instead we want to know precisely when these lapses will occur so that we can intervene to prevent them
:::

-----------------------------------------------------------------------------

## Lapse Prediction for AUD

- 151 individuals with moderate to severe AUD

- Early in recovery (1-8 weeks)

- Committed to abstinence throughout study

- Followed with sensing for up to 3 months
  - Ecological Momentary Assessments
  - Geolocation
  - Smartphone Communications

\

![](https://github.com/jjcurtin/slide_decks/blob/main/images/risk1_pi_wide.png?raw=true){.absolute bottom=0}

::: {.notes}
So let me transition now to describing how we are taking the first steps toward developing this monitoring and support system for SUD

We have recently completed a NIAAA funded project where we collected data from 151 participants who were in early recovery from a moderate to severe alcohol use disorder.  

These participants were committed to abstinence at the start of the study and we followed them for up to 3 months, collecting a variety of personal sensing data streams including the three I just mentioned.

Our broad goal was to develop a monitoring and support system that could both predict future lapses and understand the risk factors contributing to those predicted lapses so that we can recommend appropriate lifestyle adjustements and supports in advance

And critically, this system must perform well enough to be useful when applied to individuals.  

In other words, we are not looking to find coarse group-level predictors of lapses but instead to make predictions for specific individuals at specific moments in time that are actionable and useful for them.
:::

-----------------------------------------------------------------------------

## Participant Characteristics


::: {.notes}
Let me begin by giving you a sense of the characteristics of the sample we recruited and will use to train the models for our system.

To start, this is a sample of individuals with a moderate to severe presentation of alcohol use disorder based on their symptom counts.  They were all people who were experiencing very substantial problems in their lives due to their alcohol use.
:::

-----------------------------------------------------------------------------

## Participant Characteristics

```{r}
#| label: figs_ema_demographics
#| fig-height: 6
#| fig-width: 10

source(here::here("figs/risk/figs_ema_demographics.R"))
cowplot::plot_grid(fig_age, fig_sex, fig_income, fig_ms, fig_educ, fig_race, nrow = 2, ncol = 3)
```

::: {.notes}

We had reasonable diversity across many participant characteristics including age, sex at birth, martial status, education, and income

However, given the methods we used for recruiting, we have very little racial and ethnic diversity in the sample.  The sample is predominately white and non-Hispanic.

I'll return to this later both when we evaluate issues of algorithmic fairness and when I talk about another, larger NIDA funded project where we are correcting this issue of racial and ethnic representation in our models.
:::

-----------------------------------------------------------------------------

## Ecological Momentary Assessments 

Unreported lapses 

  - Date/Time

Current Experiences

  - Craving
  - Affect
  - Recent risky situations
  - Recent stressful events
  - Recent pleasant event

Future Expectations

  - Risky situations
  - Stressful events
  - Abstinence Confidence

![](https://github.com/jjcurtin/slide_decks/blob/main/images/ema_hand.png?raw=true){.absolute bottom=0 right=50 width=45%}

::: {.notes}
So let me also tell you a bit more about the 4x daily EMA we collected for three months during their study participation  

On each EMA, participants reported the date and time of any lapses back to alcohol use that they hadn’t previously reported. These lapse reports are used for the lapse outcomes that we train our models to predict.  And these laspes were also confirmed by study staff during lab visits using a follow-back procedure.

All of the EMAs also asked participants about their current craving, affective valence and arousal, recent risky situations, and recent stressful and pleasant events since their last EMA.

And on the first EMA each day, they also reported any future risky situations and stressful events that they expected in the next week and their confidence that they would remain abstinent. 
:::

-----------------------------------------------------------------------------

## Model Predictions 

- Predict hour-by-hour probability of [future lapse]{style="color: blue;"}

\

- Lapse window widths
  - Next week 
  - Next day
  - Next hour 

::: {.notes}
OK, now that we've talked about sensing, I want to transition to training models to use features from these raw signals to predict lapses.

For our purposes today I wont dive deep into the machine learning methods but let me highlight a few high level details 

We used features from these sensed signals that I just described to make predictions about the hour-by-hour probability of a future lapse.  We are developing separate models for three future lapse windows – lapses in the next week, lapses in the next day, and lapses in the next hour.  
:::

-----------------------------------------------------------------------------

## Model Predictions 

- Predict hour-by-hour probability of [future lapse]{style="color: blue;"}

\

- Lapse window widths
  - Next week 
  - Next day
  - Next hour 

::: {.notes}
For example, if I was in recovery from an AUD, I could use these models to generate the probability that I would lapse after this symposium ends at 5 pm. One model would generate the probability I would lapse at some point between 5 pm today and 5 pm next Friday, the second would predict the probability that I would lapse between 5 pm today and 5 pm tomorrow and the third and most temporally precise model would provide the probability that I would lapse in the next hour, between 5pm today and 6pm today.  

And of course, all of the models would only use data collected prior to 5 pm today so that they are “predicting”, in the full sense of the word, into the future and not just demonstrating an association.
:::

-----------------------------------------------------------------------------

## Model Performance

::: {.columns}
:::: {.column width="50%"}

The Area under the Receiver Operating Characteristic Curve ([auROC]{style="color: blue;"}) indicates:

- Probability that any true lapse is scored higher than any true no-lapse

- Random performance:  auROC = 0.5 
- Perfect performance: auROC = 1.0 


:::::{.callout-tip icon=false}
## Rules of thumb for auROC 
.70 - .80 is considered fair  
.80 - .90 is considered good  
\> .90 is considered excellent  
:::::

::::

:::: {.column width="50%"}

<!--Blank-->

::::
:::

::: {.notes}
UPDATE TO DESCRIBE ACCURACY FIRST BUT THEN auROC

So the range of auROCs is approximately .5 - 1.0 

but the auROC also has an intuitive interpretation that I want you to understand.  

Its value represents the probability that any randomly selected positive observation, in our case, a lapse, will be assigned a higher probability score than a randomly selected negative observation where no lapse occurs.

So, for example, that random classifier would only have a 50% chance of predicting a higher risk score for any specific lapse vs. a no-lapse period.  And conversely, the perfect classifier would have a 100% chance of scoring that lapse event higher than a no-lapse event.  



[PAUSE]

And to be clear, we believe all three of these models to have clinically implementable levels of performance such that we can make meaningful decisions about the probability of a future lapse for individual participants at specfic moments or windows in time.
:::

-----------------------------------------------------------------------------

## Model Performance: Excellent auROCs

::: {.columns}
:::: {.column width="50%"}

The Area under the Receiver Operating Characteristic Curve ([auROC]{style="color: blue;"}) indicates:

- Probability that any true lapse is scored higher than any true no-lapse

- Random performance:  auROC = 0.5 
- Perfect performance: auROC = 1.0 


:::::{.callout-tip icon=false}
## Rules of thumb for auROC 
.70 - .80 is considered fair  
.80 - .90 is considered good  
\> .90 is considered excellent  
:::::

::::

:::: {.column width="50%"}

```{r}
#| label: figs_auroc_ci
#| fig-height: 5
#| fig-width: 5

source(here::here("figs/risk/figs_ema_probability.R"))
fig_auroc_ci
```

::::
:::

::: {.notes}
UPDATE TO DESCRIBE ACCURACY FIRST BUT THEN auROC

So the range of auROCs is approximately .5 - 1.0 

but the auROC also has an intuitive interpretation that I want you to understand.  

Its value represents the probability that any randomly selected positive observation, in our case, a lapse, will be assigned a higher probability score than a randomly selected negative observation where no lapse occurs.

So, for example, that random classifier would only have a 50% chance of predicting a higher risk score for any specific lapse vs. a no-lapse period.  And conversely, the perfect classifier would have a 100% chance of scoring that lapse event higher than a no-lapse event.  


[PAUSE]

And to be clear, we believe all three of these models to have clinically implementable levels of performance such that we can make meaningful decisions about the probability of a future lapse for individual participants at specfic moments or windows in time.
:::

-----------------------------------------------------------------------------

## Model Performance: Well Calibrated

::: {.columns}
:::: {.column width="50%"}
DO use lapse probability

- [auROCs range from 0.90 - 0.93]{style="color: gray;"}
- Probabilities are calibrated and ordinal
- Provides fine gradations of relative risk for clinical decision-making
::::

:::: {.column width="50%"}
```{r}
#| label: fig_cal
#| fig-height: 6
#| fig-width: 6

fig_cal
```
::::
:::

::: {.notes}
And critically, these probabilities are very well calibrated and at least ordinal in their relationship with the true probability that a lapse will occur.   

On the right, I am showing you a simple calibration plot.  On the x-axis, I've binned predicted lapse probabilities into bin widths of 10 percent and for each of these bins, I display the actual observed probability of lapses for observations in that bin.  

If the probabilities were perfectly calibrated, the bin means would all fall on the dotted line with the bin from 0 - 10 having an observed probability of .05, the bin from 10 - 20 having a probability of .15, and so on.  And this is essentially what we see for our models.

Given this, we believe that the lapse probabilities can provide precise, fine gradations of risk for clinical decision making.
:::

-----------------------------------------------------------------------------

## Algorithmic Fairness

::: {.columns}
:::: {.column width="35%"}
::::

:::: {.column width="65%"}
::::
:::

::: {.notes}
[PAUSE]

But, not surprisingly given what I told you earlier about the characteristics of our training data, there is important bad news to share as well.

When we evaluate model performance, it is critical that we look at performance in protected groups.  And too often, these analyses are not done or reported.  

Its only very recently that we have begin to take this seriously and we must.  If we hope to use our system to address existing dispartities in SUD outcomes then our models must perform well with all groups, regardless of their privilege or the use of these models may exacerbate rather than reduce existing mental healthcare disparities.
:::

-----------------------------------------------------------------------------

## Algorithmic Fairness

::: {.columns}
:::: {.column width="35%"}
- Substantially poorer performance if not white/non-hispanic
::::

:::: {.column width="65%"}
```{r}
#| label: figs_fairema_ci
#| fig-height: 6
#| fig-width: 8

source(here::here("figs/risk/figs_fairema_ci.R"))
cowplot::plot_grid(fig_race, NULL, NULL, NULL)
```

::::
:::

::: {.notes}
[PAUSE]

And our models have some serious but unfortunately not unexpected problems.

On the right, these are preliminary analyses looking at performance across a variety of binary groups defined by priviledge with respect to SUD treatment access and/or outcomes.  

From these analyses, it is clear that our models perform substantially worse when predicing lapse for anyone who isnt white and non-hispanic.  And this was expected given the lack of racial and ethinic diversity in the sample.
:::

-----------------------------------------------------------------------------

## Algorithmic Fairness

::: {.columns}
:::: {.column width="35%"}
- [Substantially poorer performance if not white/non-hispanic]{style="color: gray;"}

\

- Meaningfully poorer performance for other less priviledged groups

\

- Not just due to under-representation in training data
::::

:::: {.column width="65%"}
```{r}
#| label: figs_fairema_ci-2
#| fig-height: 6
#| fig-width: 8

source(here::here("figs/risk/figs_fairema_ci.R"))
cowplot::plot_grid(fig_race, fig_income, fig_sex, fig_age)
```

::::
:::

::: {.notes}
UPDATE TO ADD SOLUTIONS?



However, there are also some, though smaller, performance issues for other less privileged groups, even when we had reasonable diversity regarding those characteristics in the sample.  And this highlights other sources of potential bias. 

For example, when selecting which EMA questions to ask participants, we based this on domain expertise from decades of research on the risk factors for lapses.  However, that research was done with predominately white, predominately male participants who often had other privileges that allowed for them to participate in research.  Given this, it may not be surprising that when we use this literature to select EMA items to measure, we may fail to include items that might tap lapse risk for people who are not white men.

I'll come back to this later when talking about our NIDA project and next steps and I hope we can discuss this too during the question period.
:::

-----------------------------------------------------------------------------
 
## NIDA Project: A Larger, More Diverse Sample 

- Recruiting ~ 300 patients in recovery from Opioid Use Disorder 
- National sample (size; diversity: demographics, location)
- More variation in stage of recovery (1 – 6 months at start)
- 12 months of monitoring
- Closer to real implementation methods


![](https://github.com/jjcurtin/slide_decks/blob/main/images/risk2_pi_wide.png?raw=true){.absolute bottom=0}

::: {.notes}
With respect to the diversity of the training data, we are now collecting data for a NIDA funded project where we are specifically recruiting for racial, ethnic, and geographic diversity across the entire United States.

We are also recruiting for people at different stages in their recovery and following them for a longer period of time – up to 12 months.  We are scheduled to complete data collection for this project in December of this year.
:::

-----------------------------------------------------------------------------

## Sensing Geolocation and Communcations

- Increase performance overall and in subgroups (more fair?)
- Lower sensing burden
- More (distinct) risk features for intervention recommendations!

::: {.notes}
Second, as our monitoring and support system continues to mature, we will want a richer, broader set of lapse risk features so that we can distinguish better between different situations that require different supports. We can do this by engineering features from our location and communication signals, which tap into different experiences than what we measure by EMA.

And as an added benefit, the use of passive sensing rather than EMA may also lower the patient burden of using these systems long term.

Let's take a look at what we can get from geolocation and communications signals to provide you with some intuition about how we think this will work.
:::

-----------------------------------------------------------------------------

## {#gps_detection_1 data-menu-title="GPS detection, wide view" background-image="https://dionysus.psych.wisc.edu/present/john_gps_wide.png" background-size="100%" background-position="bottom" background-repeat="none"}


::: {.notes}
Here is a wide view of my moment-by-moment location detected by a GPS app over a month when we were first experimenting with this sensing method.  The app recorded the paths that I traveled, with movement by car in green and running in blue.

The red dots indicate places that I stopped to visit for at least a few minutes.

And although not displayed here, the app recorded the days and exact times that I was at each of these locations.

From these data, you can immediately see that I am runner, with long runs leaving from downtown Madison and frequent trail runs on the weekends in the county and state parks to the west and northwest.
:::

-----------------------------------------------------------------------------

## {#gps_detection_2 data-menu-title="GPS detection, zoomed" background-image="https://dionysus.psych.wisc.edu/present/john_gps_zoom.png" background-size="100%" background-position="bottom" background-repeat="none"}


::: {.notes}
Zooming in to the Madison isthmus, these data show that I drove my children halfway around the lake each morning to their elementary school.  And from these data we might be able to detect those stressful mornings when getting my young kids dressed and fed didn't go as planned and we were late, sometimes **very late**, to school!

The app recorded my daily running commute through downtown Madison to and from my office.  From this, we can observe my longs days at the office and also those days that I skipped out.

Looking at the red dots indicating the places I visit, the app can detect the restaurants, bars, and coffee shops where I eat, drink and socialize.  We can use public map data to identify these places and make inferences about what I do there.
:::

-----------------------------------------------------------------------------

## ...Imagine my text messages...

![smartphone_uber.png](https://github.com/jjcurtin/lectures/blob/main/images/smartphone_uber.png?raw=true){.absolute top="15%" width="50%" height="auto"}\ 

::: {.notes}
In addition to geolocation, we also collected my smartphone communications logs and even the content of my text messages.

And no such luck, I don't plan to show you my actual text messages!

But imagine what we could learn about me from the patterns of my communications - Who I was calling, when I made those calls, and even the content of what I sent and received by text message.
:::

-----------------------------------------------------------------------------

## Context is Critical

<!--intentional blank page-->

::: {.notes}
We believe we can improve the predictive strength of these geolocation and communication signals even further by identifying the specific people and places that make us happy or sad or stressed, those that we perceive support our mental health and recovery and those who undermine it.

we gather this contextual information quickly by asking a few key questions about the people and places we interact with frequently over the first couple of months that we record these signals.  and we can identify these frequent contacts and locations directly from these signals.
:::

-----------------------------------------------------------------------------

## Beyond Prediction: Personalized Recommendations 

::: columns

::: {.column width="50%"}
```{r}
#| label: figs_tr2
#| fig-height: 3
#| fig-width: 5

source(here::here("figs/opt/figs_opt_shaps.R"))
fig_shap_ex1
```
:::

::: {.column width="50%"}

:::
:::

::: columns

::: {.column width="50%"}
```{r}
#| label: figs_bl2
#| fig-height: 3
#| fig-width: 5

fig_shap_ex1
```
:::

::: {.column width="50%"}
```{r}
#| label: figs_br2
#| fig-height: 3
#| fig-width: 5

fig_shap_ex1
```
:::
:::

::: {.notes}

We can get more than just the days when lapses are probable from these models.

We can also begin to use tools from the emerging field of interpretable AI to understand WHY they may occur

- For example, today one DTx user may show a high lapse probability and the model may have assigned that probability because they have been craving a lot recently. For that person, we could recommend urge surfing techniques and provide them support doing it within the DTx. 

- A second person might have similarly high lapse probability but instead because they have lapsed a few times in recent weeks. They could be encouraged to complete activities designed to increase their motivation for abstinence. 

- That same person might later have a low probability of lapsing because they have reported many recent positive activities. No intervention might be needed for this person but they could receive feedback about how their commitment to their well-being was paying off for their recovery.
:::

-----------------------------------------------------------------------------

## Optimize System Support Messages

- How to increase engagement, trust, utility, and benefits?
- Daily support messages from Next Day model based on EMA and and geolocation features

\

- Factorially manipulate (between subjects) four components of support message 
  - Lapse probability for that day
  - Recent trends in lapse probability 
  - Locally important features for that day
  - A risk relevant recommendation

\

- Measure engagement, trust, utility, and clinical outcomes

![](https://github.com/jjcurtin/slide_decks/blob/main/images/opt_pi_wide.png?raw=true){.absolute bottom=0}

::: {.notes}

FREE TALK

:::